{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gp.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "qjcJIxqd7DyA",
        "jt5djaZg62cM",
        "BLFTTvv_68vb"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wymfhs5SzEUk"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import keras.backend as K\n",
        "from keras.models import Sequential, load_model, Model,Input\n",
        "from keras.layers import Dense,GlobalAvgPool2D, Conv2D, MaxPool2D,AvgPool2D, GlobalAveragePooling2D,AveragePooling2D ,Softmax, BatchNormalization, ReLU, Dropout\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "from keras.layers import concatenate,Concatenate\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.image import imread \n",
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "\n",
        "\n",
        "# import cv"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#aug_major_minor \n",
        "train data = 896-896\n",
        "max no of images in normal=all raw+ all augmented"
      ],
      "metadata": {
        "id": "X7cDXc0Iax2L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_generation = ImageDataGenerator(rescale=1./255)\n",
        "training_set = train_data_generation.flow_from_directory('/content/drive/MyDrive/gp/50:50/AUG_MAJOR-MINOR/train',\n",
        "                                                         target_size=(224, 224),\n",
        "                                                         batch_size=32,\n",
        "                                                         class_mode='binary',seed=0)\n",
        "\n",
        "# preprocessing the testing set\n",
        "test_data_generation = ImageDataGenerator(rescale=1./255)\n",
        "testing_set = test_data_generation.flow_from_directory('/content/drive/MyDrive/gp/50:50/AUG_MAJOR-MINOR/test',\n",
        "                                                       target_size=(224, 224),\n",
        "                                                       batch_size=32,\n",
        "                                                       class_mode='binary',seed=0)\n",
        "\n",
        "val_data_generation = ImageDataGenerator(rescale=1./255)\n",
        "val_set = test_data_generation.flow_from_directory('/content/drive/MyDrive/gp/50:50/AUG_MAJOR-MINOR/val',\n",
        "                                                       target_size=(224, 224),\n",
        "                                                       batch_size=32,\n",
        "                                                       class_mode='binary',seed=0)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bN7kU425QJYO",
        "outputId": "5e1891ca-4c72-4897-fff8-403c0db7b64d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1792 images belonging to 2 classes.\n",
            "Found 170 images belonging to 2 classes.\n",
            "Found 523 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "\n",
        "true_labels = np.concatenate([testing_set.next()[1] for i in range(testing_set.__len__())])\n",
        "true_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ou2L1XMqcKa5",
        "outputId": "7a418264-8c4d-4337-f53f-5023ac9365e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1.,\n",
              "       0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
              "       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1.,\n",
              "       1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1.,\n",
              "       0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0.,\n",
              "       0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0.,\n",
              "       0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "label_names =['abnormal','normal']"
      ],
      "metadata": {
        "id": "BMu9CgE3cPjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def densenet(img_shape, n_class,f=32):\n",
        "  repetitions = [6, 12, 24, 16]\n",
        "  \n",
        "  def bn_rl_conv(model, f, k=1, s=1, p='same'):\n",
        "    model = BatchNormalization()(model)\n",
        "    model = ReLU()(model)\n",
        "    model = Conv2D(f, k, strides=s, padding=p)(model)\n",
        "    return model\n",
        "  \n",
        "  \n",
        "  def dense_block(conc, r):\n",
        "    for i in range(r):\n",
        "      model = bn_rl_conv(conc, 4*f)\n",
        "      model = bn_rl_conv(model, f, 3)\n",
        "      conc = Concatenate()([conc, model])\n",
        "    return conc\n",
        "  \n",
        "  \n",
        "  def transition_block(model):\n",
        "    model = bn_rl_conv(model, K.int_shape(model)[-1] // 2)\n",
        "    model = AvgPool2D(2, strides=2, padding='same')(model)\n",
        "    return model\n",
        "  \n",
        "  \n",
        "  input = Input(img_shape)\n",
        "  \n",
        "  model = Conv2D(64, 7, strides=2, padding='same')(input)\n",
        "  model = MaxPool2D(3, strides=2, padding='same')(model)\n",
        "  \n",
        "  for r in repetitions:\n",
        "    d = dense_block(model, r)\n",
        "    model = transition_block(d)\n",
        "  \n",
        "  model = GlobalAvgPool2D()(d)\n",
        "  \n",
        "  output = Dense(n_class, activation='sigmoid')(model)\n",
        "  \n",
        "  model = Model(input, output)\n",
        "  return model\n",
        "\n"
      ],
      "metadata": {
        "id": "ueAVk5RGPtX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_model_major_minor= densenet([224,224,3],2)\n",
        "_model_major_minor.summary()"
      ],
      "metadata": {
        "id": "ETyX1dAObbmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "early_s=EarlyStopping(monitor='val_accuracy',patience=15,mode='max',restore_best_weights=True)\n",
        "\n",
        "_model_major_minor.compile(optimizer='adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "history_major_minor=_model_major_minor.fit(x=training_set, validation_data=val_set, epochs=150,callbacks=([early_s]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDv5zXCZbbjo",
        "outputId": "e27e6541-4f98-4de8-b40e-e97b60ff28f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "56/56 [==============================] - 402s 7s/step - loss: 0.8199 - accuracy: 0.6864 - val_loss: 0.9567 - val_accuracy: 0.4742\n",
            "Epoch 2/150\n",
            "56/56 [==============================] - 46s 826ms/step - loss: 0.6274 - accuracy: 0.7087 - val_loss: 0.6717 - val_accuracy: 0.6004\n",
            "Epoch 3/150\n",
            "56/56 [==============================] - 46s 821ms/step - loss: 0.6111 - accuracy: 0.7427 - val_loss: 0.7365 - val_accuracy: 0.6654\n",
            "Epoch 4/150\n",
            "56/56 [==============================] - 47s 836ms/step - loss: 0.5003 - accuracy: 0.7662 - val_loss: 0.8361 - val_accuracy: 0.4283\n",
            "Epoch 5/150\n",
            "56/56 [==============================] - 46s 816ms/step - loss: 0.5361 - accuracy: 0.7712 - val_loss: 0.8238 - val_accuracy: 0.4876\n",
            "Epoch 6/150\n",
            "56/56 [==============================] - 46s 819ms/step - loss: 0.4770 - accuracy: 0.7807 - val_loss: 0.6279 - val_accuracy: 0.6329\n",
            "Epoch 7/150\n",
            "56/56 [==============================] - 46s 814ms/step - loss: 0.4623 - accuracy: 0.7879 - val_loss: 0.6972 - val_accuracy: 0.5985\n",
            "Epoch 8/150\n",
            "56/56 [==============================] - 46s 813ms/step - loss: 0.4623 - accuracy: 0.8069 - val_loss: 0.8775 - val_accuracy: 0.7055\n",
            "Epoch 9/150\n",
            "56/56 [==============================] - 46s 813ms/step - loss: 0.4707 - accuracy: 0.7712 - val_loss: 0.4054 - val_accuracy: 0.8203\n",
            "Epoch 10/150\n",
            "56/56 [==============================] - 45s 806ms/step - loss: 0.4438 - accuracy: 0.7997 - val_loss: 0.8359 - val_accuracy: 0.6692\n",
            "Epoch 11/150\n",
            "56/56 [==============================] - 45s 808ms/step - loss: 0.4308 - accuracy: 0.8086 - val_loss: 2.3113 - val_accuracy: 0.6157\n",
            "Epoch 12/150\n",
            "56/56 [==============================] - 45s 806ms/step - loss: 0.4085 - accuracy: 0.8231 - val_loss: 0.5684 - val_accuracy: 0.7247\n",
            "Epoch 13/150\n",
            "56/56 [==============================] - 45s 806ms/step - loss: 0.4025 - accuracy: 0.8253 - val_loss: 0.5420 - val_accuracy: 0.7400\n",
            "Epoch 14/150\n",
            "56/56 [==============================] - 45s 807ms/step - loss: 0.3841 - accuracy: 0.8393 - val_loss: 0.7254 - val_accuracy: 0.6501\n",
            "Epoch 15/150\n",
            "56/56 [==============================] - 45s 806ms/step - loss: 0.3754 - accuracy: 0.8387 - val_loss: 2.1228 - val_accuracy: 0.7094\n",
            "Epoch 16/150\n",
            "56/56 [==============================] - 45s 806ms/step - loss: 0.3722 - accuracy: 0.8382 - val_loss: 0.7186 - val_accuracy: 0.6520\n",
            "Epoch 17/150\n",
            "56/56 [==============================] - 45s 806ms/step - loss: 0.3615 - accuracy: 0.8449 - val_loss: 0.4231 - val_accuracy: 0.8050\n",
            "Epoch 18/150\n",
            "56/56 [==============================] - 45s 806ms/step - loss: 0.3361 - accuracy: 0.8571 - val_loss: 0.5471 - val_accuracy: 0.7954\n",
            "Epoch 19/150\n",
            "56/56 [==============================] - 45s 807ms/step - loss: 0.3281 - accuracy: 0.8733 - val_loss: 0.7148 - val_accuracy: 0.7094\n",
            "Epoch 20/150\n",
            "56/56 [==============================] - 45s 812ms/step - loss: 0.3263 - accuracy: 0.8717 - val_loss: 0.4197 - val_accuracy: 0.8298\n",
            "Epoch 21/150\n",
            "56/56 [==============================] - 45s 811ms/step - loss: 0.3176 - accuracy: 0.8694 - val_loss: 2.1934 - val_accuracy: 0.8375\n",
            "Epoch 22/150\n",
            "56/56 [==============================] - 45s 805ms/step - loss: 0.3161 - accuracy: 0.8683 - val_loss: 4.7008 - val_accuracy: 0.7591\n",
            "Epoch 23/150\n",
            "56/56 [==============================] - 45s 807ms/step - loss: 0.3240 - accuracy: 0.8588 - val_loss: 1.6530 - val_accuracy: 0.4818\n",
            "Epoch 24/150\n",
            "56/56 [==============================] - 45s 806ms/step - loss: 0.3067 - accuracy: 0.8728 - val_loss: 0.8331 - val_accuracy: 0.6769\n",
            "Epoch 25/150\n",
            "56/56 [==============================] - 46s 813ms/step - loss: 0.2931 - accuracy: 0.8778 - val_loss: 0.5279 - val_accuracy: 0.7897\n",
            "Epoch 26/150\n",
            "56/56 [==============================] - 46s 812ms/step - loss: 0.3075 - accuracy: 0.8783 - val_loss: 2.8766 - val_accuracy: 0.6520\n",
            "Epoch 27/150\n",
            "56/56 [==============================] - 46s 816ms/step - loss: 0.3121 - accuracy: 0.8694 - val_loss: 0.3493 - val_accuracy: 0.8853\n",
            "Epoch 28/150\n",
            "56/56 [==============================] - 45s 810ms/step - loss: 0.2797 - accuracy: 0.8817 - val_loss: 0.4330 - val_accuracy: 0.8451\n",
            "Epoch 29/150\n",
            "56/56 [==============================] - 45s 811ms/step - loss: 0.2671 - accuracy: 0.8906 - val_loss: 0.5479 - val_accuracy: 0.8088\n",
            "Epoch 30/150\n",
            "56/56 [==============================] - 45s 810ms/step - loss: 0.2748 - accuracy: 0.8884 - val_loss: 0.4358 - val_accuracy: 0.7935\n",
            "Epoch 31/150\n",
            "56/56 [==============================] - 45s 809ms/step - loss: 0.2570 - accuracy: 0.8973 - val_loss: 0.3057 - val_accuracy: 0.8776\n",
            "Epoch 32/150\n",
            "56/56 [==============================] - 45s 809ms/step - loss: 0.2655 - accuracy: 0.8878 - val_loss: 89.8799 - val_accuracy: 0.4818\n",
            "Epoch 33/150\n",
            "56/56 [==============================] - 45s 810ms/step - loss: 0.2828 - accuracy: 0.8906 - val_loss: 0.4365 - val_accuracy: 0.8298\n",
            "Epoch 34/150\n",
            "56/56 [==============================] - 45s 809ms/step - loss: 0.2855 - accuracy: 0.8862 - val_loss: 0.3020 - val_accuracy: 0.8681\n",
            "Epoch 35/150\n",
            "56/56 [==============================] - 45s 808ms/step - loss: 0.2762 - accuracy: 0.8850 - val_loss: 0.5863 - val_accuracy: 0.7285\n",
            "Epoch 36/150\n",
            "56/56 [==============================] - 45s 810ms/step - loss: 0.2667 - accuracy: 0.8951 - val_loss: 0.5339 - val_accuracy: 0.7476\n",
            "Epoch 37/150\n",
            "56/56 [==============================] - 45s 809ms/step - loss: 0.2393 - accuracy: 0.9079 - val_loss: 0.7622 - val_accuracy: 0.7151\n",
            "Epoch 38/150\n",
            "56/56 [==============================] - 45s 810ms/step - loss: 0.2335 - accuracy: 0.9074 - val_loss: 1.2220 - val_accuracy: 0.6157\n",
            "Epoch 39/150\n",
            "56/56 [==============================] - 45s 809ms/step - loss: 0.2504 - accuracy: 0.8956 - val_loss: 0.3601 - val_accuracy: 0.8719\n",
            "Epoch 40/150\n",
            "56/56 [==============================] - 45s 810ms/step - loss: 0.2309 - accuracy: 0.9051 - val_loss: 0.3757 - val_accuracy: 0.8719\n",
            "Epoch 41/150\n",
            "56/56 [==============================] - 45s 810ms/step - loss: 0.2254 - accuracy: 0.9113 - val_loss: 0.3673 - val_accuracy: 0.8604\n",
            "Epoch 42/150\n",
            "56/56 [==============================] - 46s 811ms/step - loss: 0.2086 - accuracy: 0.9174 - val_loss: 0.4008 - val_accuracy: 0.8642\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_model_major_minor.save('/content/drive/MyDrive/gp/Major_Minor.h5')\n"
      ],
      "metadata": {
        "id": "MLh5Zg5td5uA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction=_model_major_minor.predict(testing_set)\n",
        "classes_x=np.argmax(prediction,axis=1)\n",
        "classes_x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMhnC6pcbbhI",
        "outputId": "70e01167-61f2-41ea-807b-3699d676df57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1,\n",
              "       0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,\n",
              "       0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1,\n",
              "       0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
              "       1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "       0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cf = confusion_matrix(y_true= true_labels, y_pred= classes_x)\n",
        "score = accuracy_score(y_true= true_labels, y_pred=classes_x)\n",
        "print(cf)\n",
        "print('the model performane is: ', score*100, \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QfoLNJSZbbd_",
        "outputId": "462b4ea7-152d-4f16-d892-6055a1fb95a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[94 11]\n",
            " [ 9 56]]\n",
            "the model performane is:  88.23529411764706 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(true_labels, classes_x,target_names=label_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q56PKpBCcw0z",
        "outputId": "122f65ed-9a74-4066-cca4-0371c66daece"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    abnormal       0.91      0.90      0.90       105\n",
            "      normal       0.84      0.86      0.85        65\n",
            "\n",
            "    accuracy                           0.88       170\n",
            "   macro avg       0.87      0.88      0.88       170\n",
            "weighted avg       0.88      0.88      0.88       170\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_model_major_minor.fit(x=training_set, validation_data=val_set, epochs=150,callbacks=([early_s]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUPSERrXnMz6",
        "outputId": "31665077-cb4c-4509-c3f8-21097811b9bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "56/56 [==============================] - 46s 822ms/step - loss: 0.2721 - accuracy: 0.8934 - val_loss: 12.5908 - val_accuracy: 0.7228\n",
            "Epoch 2/150\n",
            "56/56 [==============================] - 46s 815ms/step - loss: 0.3636 - accuracy: 0.8549 - val_loss: 5.5273 - val_accuracy: 0.6444\n",
            "Epoch 3/150\n",
            "56/56 [==============================] - 47s 842ms/step - loss: 0.3137 - accuracy: 0.8750 - val_loss: 1.1546 - val_accuracy: 0.6635\n",
            "Epoch 4/150\n",
            "56/56 [==============================] - 46s 827ms/step - loss: 0.3272 - accuracy: 0.8666 - val_loss: 0.4167 - val_accuracy: 0.8222\n",
            "Epoch 5/150\n",
            "56/56 [==============================] - 46s 828ms/step - loss: 0.3143 - accuracy: 0.8717 - val_loss: 0.4333 - val_accuracy: 0.8164\n",
            "Epoch 6/150\n",
            "56/56 [==============================] - 47s 832ms/step - loss: 0.3032 - accuracy: 0.8772 - val_loss: 0.3479 - val_accuracy: 0.8585\n",
            "Epoch 7/150\n",
            "56/56 [==============================] - 46s 817ms/step - loss: 0.2545 - accuracy: 0.8984 - val_loss: 0.4358 - val_accuracy: 0.8375\n",
            "Epoch 8/150\n",
            "56/56 [==============================] - 46s 817ms/step - loss: 0.2843 - accuracy: 0.8733 - val_loss: 0.4085 - val_accuracy: 0.8356\n",
            "Epoch 9/150\n",
            "56/56 [==============================] - 46s 816ms/step - loss: 0.2511 - accuracy: 0.9001 - val_loss: 0.4709 - val_accuracy: 0.7686\n",
            "Epoch 10/150\n",
            "56/56 [==============================] - 46s 821ms/step - loss: 0.2420 - accuracy: 0.9012 - val_loss: 0.4171 - val_accuracy: 0.8222\n",
            "Epoch 11/150\n",
            "56/56 [==============================] - 46s 814ms/step - loss: 0.2286 - accuracy: 0.9023 - val_loss: 0.6174 - val_accuracy: 0.7553\n",
            "Epoch 12/150\n",
            "56/56 [==============================] - 47s 835ms/step - loss: 0.2814 - accuracy: 0.8890 - val_loss: 0.4498 - val_accuracy: 0.8260\n",
            "Epoch 13/150\n",
            "56/56 [==============================] - 45s 811ms/step - loss: 0.2216 - accuracy: 0.9141 - val_loss: 0.5438 - val_accuracy: 0.7763\n",
            "Epoch 14/150\n",
            "56/56 [==============================] - 45s 811ms/step - loss: 0.2208 - accuracy: 0.9102 - val_loss: 0.3255 - val_accuracy: 0.8509\n",
            "Epoch 15/150\n",
            "56/56 [==============================] - 45s 811ms/step - loss: 0.2011 - accuracy: 0.9196 - val_loss: 0.7078 - val_accuracy: 0.8470\n",
            "Epoch 16/150\n",
            "56/56 [==============================] - 46s 816ms/step - loss: 0.2221 - accuracy: 0.9090 - val_loss: 0.3406 - val_accuracy: 0.8738\n",
            "Epoch 17/150\n",
            "56/56 [==============================] - 45s 811ms/step - loss: 0.2030 - accuracy: 0.9196 - val_loss: 0.4154 - val_accuracy: 0.8623\n",
            "Epoch 18/150\n",
            "56/56 [==============================] - 47s 836ms/step - loss: 0.2086 - accuracy: 0.9174 - val_loss: 0.5959 - val_accuracy: 0.7744\n",
            "Epoch 19/150\n",
            "56/56 [==============================] - 46s 813ms/step - loss: 0.1965 - accuracy: 0.9280 - val_loss: 0.8026 - val_accuracy: 0.7361\n",
            "Epoch 20/150\n",
            "56/56 [==============================] - 45s 812ms/step - loss: 0.1938 - accuracy: 0.9241 - val_loss: 0.3773 - val_accuracy: 0.8528\n",
            "Epoch 21/150\n",
            "56/56 [==============================] - 46s 813ms/step - loss: 0.1970 - accuracy: 0.9208 - val_loss: 5.1334 - val_accuracy: 0.6826\n",
            "Epoch 22/150\n",
            "56/56 [==============================] - 46s 813ms/step - loss: 0.1855 - accuracy: 0.9314 - val_loss: 1.7863 - val_accuracy: 0.5698\n",
            "Epoch 23/150\n",
            "56/56 [==============================] - 46s 812ms/step - loss: 0.1836 - accuracy: 0.9280 - val_loss: 0.4640 - val_accuracy: 0.8222\n",
            "Epoch 24/150\n",
            "56/56 [==============================] - 46s 812ms/step - loss: 0.1839 - accuracy: 0.9263 - val_loss: 0.7112 - val_accuracy: 0.8011\n",
            "Epoch 25/150\n",
            "56/56 [==============================] - 45s 812ms/step - loss: 0.1437 - accuracy: 0.9448 - val_loss: 0.4137 - val_accuracy: 0.8585\n",
            "Epoch 26/150\n",
            "56/56 [==============================] - 46s 812ms/step - loss: 0.1571 - accuracy: 0.9414 - val_loss: 0.4673 - val_accuracy: 0.8432\n",
            "Epoch 27/150\n",
            "56/56 [==============================] - 46s 813ms/step - loss: 0.1736 - accuracy: 0.9319 - val_loss: 0.4113 - val_accuracy: 0.8585\n",
            "Epoch 28/150\n",
            "56/56 [==============================] - 45s 812ms/step - loss: 0.1519 - accuracy: 0.9381 - val_loss: 0.4912 - val_accuracy: 0.8375\n",
            "Epoch 29/150\n",
            "56/56 [==============================] - 47s 835ms/step - loss: 0.1568 - accuracy: 0.9342 - val_loss: 0.4016 - val_accuracy: 0.8566\n",
            "Epoch 30/150\n",
            "56/56 [==============================] - 45s 810ms/step - loss: 0.1494 - accuracy: 0.9431 - val_loss: 0.5067 - val_accuracy: 0.8470\n",
            "Epoch 31/150\n",
            "56/56 [==============================] - 46s 811ms/step - loss: 0.1387 - accuracy: 0.9487 - val_loss: 0.3538 - val_accuracy: 0.8795\n",
            "Epoch 32/150\n",
            "56/56 [==============================] - 45s 810ms/step - loss: 0.1216 - accuracy: 0.9520 - val_loss: 0.3772 - val_accuracy: 0.8776\n",
            "Epoch 33/150\n",
            "56/56 [==============================] - 45s 810ms/step - loss: 0.1386 - accuracy: 0.9492 - val_loss: 0.6469 - val_accuracy: 0.7973\n",
            "Epoch 34/150\n",
            "56/56 [==============================] - 45s 810ms/step - loss: 0.1148 - accuracy: 0.9554 - val_loss: 0.6622 - val_accuracy: 0.8031\n",
            "Epoch 35/150\n",
            "56/56 [==============================] - 45s 811ms/step - loss: 0.1316 - accuracy: 0.9492 - val_loss: 1.3056 - val_accuracy: 0.7476\n",
            "Epoch 36/150\n",
            "56/56 [==============================] - 46s 815ms/step - loss: 0.1174 - accuracy: 0.9548 - val_loss: 0.3815 - val_accuracy: 0.8948\n",
            "Epoch 37/150\n",
            "56/56 [==============================] - 45s 810ms/step - loss: 0.1038 - accuracy: 0.9626 - val_loss: 0.4163 - val_accuracy: 0.8719\n",
            "Epoch 38/150\n",
            "56/56 [==============================] - 46s 816ms/step - loss: 0.0971 - accuracy: 0.9676 - val_loss: 0.2600 - val_accuracy: 0.9044\n",
            "Epoch 39/150\n",
            "56/56 [==============================] - 45s 810ms/step - loss: 0.0997 - accuracy: 0.9665 - val_loss: 0.3542 - val_accuracy: 0.8929\n",
            "Epoch 40/150\n",
            "56/56 [==============================] - 45s 810ms/step - loss: 0.1023 - accuracy: 0.9682 - val_loss: 0.6666 - val_accuracy: 0.8241\n",
            "Epoch 41/150\n",
            "56/56 [==============================] - 45s 811ms/step - loss: 0.1268 - accuracy: 0.9453 - val_loss: 0.3434 - val_accuracy: 0.8910\n",
            "Epoch 42/150\n",
            "56/56 [==============================] - 46s 812ms/step - loss: 0.1305 - accuracy: 0.9542 - val_loss: 0.5412 - val_accuracy: 0.8738\n",
            "Epoch 43/150\n",
            "56/56 [==============================] - 45s 809ms/step - loss: 0.1379 - accuracy: 0.9464 - val_loss: 301.1436 - val_accuracy: 0.6730\n",
            "Epoch 44/150\n",
            "56/56 [==============================] - 45s 810ms/step - loss: 0.2344 - accuracy: 0.9152 - val_loss: 0.8203 - val_accuracy: 0.7094\n",
            "Epoch 45/150\n",
            "56/56 [==============================] - 45s 812ms/step - loss: 0.1306 - accuracy: 0.9537 - val_loss: 0.4043 - val_accuracy: 0.8489\n",
            "Epoch 46/150\n",
            "56/56 [==============================] - 45s 811ms/step - loss: 0.1194 - accuracy: 0.9554 - val_loss: 0.4829 - val_accuracy: 0.8662\n",
            "Epoch 47/150\n",
            "56/56 [==============================] - 45s 811ms/step - loss: 0.1216 - accuracy: 0.9520 - val_loss: 0.2971 - val_accuracy: 0.8987\n",
            "Epoch 48/150\n",
            "56/56 [==============================] - 45s 809ms/step - loss: 0.0951 - accuracy: 0.9626 - val_loss: 0.4212 - val_accuracy: 0.8948\n",
            "Epoch 49/150\n",
            "56/56 [==============================] - 45s 808ms/step - loss: 0.0766 - accuracy: 0.9743 - val_loss: 0.5780 - val_accuracy: 0.8451\n",
            "Epoch 50/150\n",
            "56/56 [==============================] - 45s 810ms/step - loss: 0.0764 - accuracy: 0.9754 - val_loss: 0.9386 - val_accuracy: 0.7897\n",
            "Epoch 51/150\n",
            "56/56 [==============================] - 45s 811ms/step - loss: 0.1096 - accuracy: 0.9581 - val_loss: 0.5087 - val_accuracy: 0.8413\n",
            "Epoch 52/150\n",
            "56/56 [==============================] - 45s 812ms/step - loss: 0.0910 - accuracy: 0.9676 - val_loss: 0.5059 - val_accuracy: 0.8470\n",
            "Epoch 53/150\n",
            "56/56 [==============================] - 46s 816ms/step - loss: 0.0828 - accuracy: 0.9743 - val_loss: 0.3362 - val_accuracy: 0.9159\n",
            "Epoch 54/150\n",
            "56/56 [==============================] - 45s 810ms/step - loss: 0.0532 - accuracy: 0.9838 - val_loss: 0.5379 - val_accuracy: 0.8489\n",
            "Epoch 55/150\n",
            "56/56 [==============================] - 45s 809ms/step - loss: 0.0597 - accuracy: 0.9782 - val_loss: 0.4822 - val_accuracy: 0.8757\n",
            "Epoch 56/150\n",
            "56/56 [==============================] - 45s 810ms/step - loss: 0.0853 - accuracy: 0.9710 - val_loss: 0.6991 - val_accuracy: 0.7763\n",
            "Epoch 57/150\n",
            "56/56 [==============================] - 45s 810ms/step - loss: 0.0816 - accuracy: 0.9704 - val_loss: 0.8695 - val_accuracy: 0.8164\n",
            "Epoch 58/150\n",
            "56/56 [==============================] - 45s 812ms/step - loss: 0.1093 - accuracy: 0.9632 - val_loss: 0.4184 - val_accuracy: 0.8834\n",
            "Epoch 59/150\n",
            "56/56 [==============================] - 45s 810ms/step - loss: 0.0707 - accuracy: 0.9777 - val_loss: 0.5055 - val_accuracy: 0.8834\n",
            "Epoch 60/150\n",
            "56/56 [==============================] - 46s 815ms/step - loss: 0.0363 - accuracy: 0.9877 - val_loss: 0.2804 - val_accuracy: 0.9216\n",
            "Epoch 61/150\n",
            "56/56 [==============================] - 45s 811ms/step - loss: 0.0452 - accuracy: 0.9855 - val_loss: 0.4329 - val_accuracy: 0.9159\n",
            "Epoch 62/150\n",
            "56/56 [==============================] - 45s 810ms/step - loss: 0.0579 - accuracy: 0.9810 - val_loss: 0.3905 - val_accuracy: 0.8815\n",
            "Epoch 63/150\n",
            "56/56 [==============================] - 45s 810ms/step - loss: 0.0661 - accuracy: 0.9743 - val_loss: 0.4277 - val_accuracy: 0.8853\n",
            "Epoch 64/150\n",
            "56/56 [==============================] - 45s 811ms/step - loss: 0.0483 - accuracy: 0.9833 - val_loss: 0.5755 - val_accuracy: 0.8623\n",
            "Epoch 65/150\n",
            "56/56 [==============================] - 45s 812ms/step - loss: 0.0615 - accuracy: 0.9805 - val_loss: 0.5180 - val_accuracy: 0.8184\n",
            "Epoch 66/150\n",
            "56/56 [==============================] - 45s 810ms/step - loss: 0.0524 - accuracy: 0.9844 - val_loss: 0.7437 - val_accuracy: 0.8356\n",
            "Epoch 67/150\n",
            "56/56 [==============================] - 45s 811ms/step - loss: 0.0391 - accuracy: 0.9844 - val_loss: 0.6596 - val_accuracy: 0.8547\n",
            "Epoch 68/150\n",
            "56/56 [==============================] - 45s 811ms/step - loss: 0.0326 - accuracy: 0.9883 - val_loss: 0.4030 - val_accuracy: 0.9082\n",
            "Epoch 69/150\n",
            "56/56 [==============================] - 45s 811ms/step - loss: 0.0184 - accuracy: 0.9939 - val_loss: 0.5677 - val_accuracy: 0.8948\n",
            "Epoch 70/150\n",
            "56/56 [==============================] - 45s 811ms/step - loss: 0.0554 - accuracy: 0.9821 - val_loss: 1.1588 - val_accuracy: 0.8451\n",
            "Epoch 71/150\n",
            "56/56 [==============================] - 45s 811ms/step - loss: 0.1051 - accuracy: 0.9676 - val_loss: 0.6780 - val_accuracy: 0.8260\n",
            "Epoch 72/150\n",
            "56/56 [==============================] - 45s 811ms/step - loss: 0.0908 - accuracy: 0.9665 - val_loss: 0.6722 - val_accuracy: 0.8585\n",
            "Epoch 73/150\n",
            "56/56 [==============================] - 45s 810ms/step - loss: 0.0556 - accuracy: 0.9844 - val_loss: 0.3312 - val_accuracy: 0.9006\n",
            "Epoch 74/150\n",
            "56/56 [==============================] - 45s 811ms/step - loss: 0.0362 - accuracy: 0.9849 - val_loss: 0.5134 - val_accuracy: 0.9120\n",
            "Epoch 75/150\n",
            "56/56 [==============================] - 46s 817ms/step - loss: 0.0420 - accuracy: 0.9860 - val_loss: 0.3668 - val_accuracy: 0.8948\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5a7db76f90>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_model_major_minor.save('/content/drive/MyDrive/gp/Major_Minor_retrain.h5')\n"
      ],
      "metadata": {
        "id": "GeGjd-b1_vz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction=_model_major_minor.predict(testing_set)\n",
        "classes_x=np.argmax(prediction,axis=1)\n",
        "\n",
        "classes_x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d745q85ucXU0",
        "outputId": "d29b588b-7835-4f68-ab80-88053c2d9746"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "       1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
              "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0,\n",
              "       1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0,\n",
              "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
              "       0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
              "       1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cf = confusion_matrix(y_true= true_labels, y_pred= classes_x)\n",
        "score = accuracy_score(y_true= true_labels, y_pred=classes_x)\n",
        "print(cf)\n",
        "print('the model performane is: ', score*100, \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGyegfRjnW8A",
        "outputId": "76ea9bee-e675-4436-93b2-d04f55c21c8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[64 41]\n",
            " [39 26]]\n",
            "the model performane is:  52.94117647058824 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(true_labels, classes_x,target_names=label_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnEa_Wi1nW5L",
        "outputId": "31f745b3-47ed-45b0-abf0-9c1a408f97a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    abnormal       0.62      0.61      0.62       105\n",
            "      normal       0.39      0.40      0.39        65\n",
            "\n",
            "    accuracy                           0.53       170\n",
            "   macro avg       0.50      0.50      0.50       170\n",
            "weighted avg       0.53      0.53      0.53       170\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#minor_minor\n",
        "448-448\\\n",
        "max no of raw data"
      ],
      "metadata": {
        "id": "RjhwKLkkqhsG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_generation = ImageDataGenerator(rescale=1./255)\n",
        "training_set = train_data_generation.flow_from_directory('/content/drive/MyDrive/gp/50:50/MINOR-MINOR/train',\n",
        "                                                         target_size=(224, 224),\n",
        "                                                         batch_size=32,\n",
        "                                                         class_mode='binary',seed=0)\n",
        "\n",
        "\n",
        "\n",
        "val_data_generation = ImageDataGenerator(rescale=1./255)\n",
        "val_set = test_data_generation.flow_from_directory('/content/drive/MyDrive/gp/50:50/MINOR-MINOR/val',\n",
        "                                                       target_size=(224, 224),\n",
        "                                                       batch_size=32,\n",
        "                                                       class_mode='binary',seed=0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5KelK-2nWtg",
        "outputId": "0fcab91b-3eab-4984-b151-fe3826ca45fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 896 images belonging to 2 classes.\n",
            "Found 503 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "true_labels=[]\n",
        "true_labels = np.concatenate([testing_set.next()[1] for i in range(testing_set.__len__())])\n",
        "true_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGXovwURq3ku",
        "outputId": "ee1bc7d9-589c-40e2-fa07-098f074232c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "       0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0.,\n",
              "       0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "       1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
              "       1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
              "       0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
              "       0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
              "       0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "       0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_model_minor_minor= densenet([224,224,3],2)\n",
        "# _model_minor_minor.summary()"
      ],
      "metadata": {
        "id": "eB1HacoIq3hb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_model_minor_minor.compile(optimizer='adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "history_minor_minor=_model_minor_minor.fit(x=training_set, validation_data=val_set, epochs=150,callbacks=([early_s]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fq7ztZrrq3eg",
        "outputId": "ffab99c0-138a-4b62-9c67-99d43c120ffa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "28/28 [==============================] - 258s 9s/step - loss: 1.0676 - accuracy: 0.7065 - val_loss: 37.9752 - val_accuracy: 0.3936\n",
            "Epoch 2/150\n",
            "28/28 [==============================] - 25s 884ms/step - loss: 0.4705 - accuracy: 0.7991 - val_loss: 2.7190 - val_accuracy: 0.3817\n",
            "Epoch 3/150\n",
            "28/28 [==============================] - 25s 883ms/step - loss: 0.4713 - accuracy: 0.7757 - val_loss: 1.4495 - val_accuracy: 0.3817\n",
            "Epoch 4/150\n",
            "28/28 [==============================] - 25s 882ms/step - loss: 0.4694 - accuracy: 0.7511 - val_loss: 1.0294 - val_accuracy: 0.3817\n",
            "Epoch 5/150\n",
            "28/28 [==============================] - 25s 880ms/step - loss: 0.4438 - accuracy: 0.8002 - val_loss: 0.9154 - val_accuracy: 0.3817\n",
            "Epoch 6/150\n",
            "28/28 [==============================] - 25s 878ms/step - loss: 0.4374 - accuracy: 0.8147 - val_loss: 1.3726 - val_accuracy: 0.3817\n",
            "Epoch 7/150\n",
            "28/28 [==============================] - 25s 880ms/step - loss: 0.3989 - accuracy: 0.8237 - val_loss: 1.5172 - val_accuracy: 0.3837\n",
            "Epoch 8/150\n",
            "28/28 [==============================] - 25s 878ms/step - loss: 0.4493 - accuracy: 0.8058 - val_loss: 1.7537 - val_accuracy: 0.3598\n",
            "Epoch 9/150\n",
            "28/28 [==============================] - 25s 889ms/step - loss: 0.3682 - accuracy: 0.8415 - val_loss: 1.3970 - val_accuracy: 0.4294\n",
            "Epoch 10/150\n",
            "28/28 [==============================] - 25s 891ms/step - loss: 0.3814 - accuracy: 0.8438 - val_loss: 0.9919 - val_accuracy: 0.6243\n",
            "Epoch 11/150\n",
            "28/28 [==============================] - 25s 880ms/step - loss: 0.3574 - accuracy: 0.8560 - val_loss: 1.3428 - val_accuracy: 0.4930\n",
            "Epoch 12/150\n",
            "28/28 [==============================] - 25s 880ms/step - loss: 0.3410 - accuracy: 0.8605 - val_loss: 0.7551 - val_accuracy: 0.6163\n",
            "Epoch 13/150\n",
            "28/28 [==============================] - 25s 892ms/step - loss: 0.3778 - accuracy: 0.8504 - val_loss: 0.7231 - val_accuracy: 0.7376\n",
            "Epoch 14/150\n",
            "28/28 [==============================] - 25s 879ms/step - loss: 0.3741 - accuracy: 0.8605 - val_loss: 9.0543 - val_accuracy: 0.4692\n",
            "Epoch 15/150\n",
            "28/28 [==============================] - 25s 880ms/step - loss: 0.3224 - accuracy: 0.8627 - val_loss: 9.8686 - val_accuracy: 0.6421\n",
            "Epoch 16/150\n",
            "28/28 [==============================] - 25s 880ms/step - loss: 0.3350 - accuracy: 0.8694 - val_loss: 1.7518 - val_accuracy: 0.6978\n",
            "Epoch 17/150\n",
            "28/28 [==============================] - 25s 879ms/step - loss: 0.3206 - accuracy: 0.8795 - val_loss: 0.9266 - val_accuracy: 0.6302\n",
            "Epoch 18/150\n",
            "28/28 [==============================] - 25s 879ms/step - loss: 0.3127 - accuracy: 0.8717 - val_loss: 2.5088 - val_accuracy: 0.6859\n",
            "Epoch 19/150\n",
            "28/28 [==============================] - 25s 879ms/step - loss: 0.2896 - accuracy: 0.8806 - val_loss: 2.2694 - val_accuracy: 0.7058\n",
            "Epoch 20/150\n",
            "28/28 [==============================] - 25s 880ms/step - loss: 0.3124 - accuracy: 0.8728 - val_loss: 1.6279 - val_accuracy: 0.6740\n",
            "Epoch 21/150\n",
            "28/28 [==============================] - 25s 878ms/step - loss: 0.2926 - accuracy: 0.8739 - val_loss: 0.9545 - val_accuracy: 0.7217\n",
            "Epoch 22/150\n",
            "28/28 [==============================] - 25s 889ms/step - loss: 0.2738 - accuracy: 0.8984 - val_loss: 1.1063 - val_accuracy: 0.7515\n",
            "Epoch 23/150\n",
            "28/28 [==============================] - 25s 877ms/step - loss: 0.2913 - accuracy: 0.8761 - val_loss: 1.7669 - val_accuracy: 0.6819\n",
            "Epoch 24/150\n",
            "28/28 [==============================] - 25s 890ms/step - loss: 0.2415 - accuracy: 0.9029 - val_loss: 0.3474 - val_accuracy: 0.8588\n",
            "Epoch 25/150\n",
            "28/28 [==============================] - 25s 884ms/step - loss: 0.2544 - accuracy: 0.8929 - val_loss: 1.6252 - val_accuracy: 0.7435\n",
            "Epoch 26/150\n",
            "28/28 [==============================] - 25s 879ms/step - loss: 0.2836 - accuracy: 0.8962 - val_loss: 0.6654 - val_accuracy: 0.7276\n",
            "Epoch 27/150\n",
            "28/28 [==============================] - 25s 878ms/step - loss: 0.2331 - accuracy: 0.9096 - val_loss: 0.5562 - val_accuracy: 0.8072\n",
            "Epoch 28/150\n",
            "28/28 [==============================] - 25s 878ms/step - loss: 0.2591 - accuracy: 0.8973 - val_loss: 0.3483 - val_accuracy: 0.8410\n",
            "Epoch 29/150\n",
            "28/28 [==============================] - 25s 879ms/step - loss: 0.2542 - accuracy: 0.9062 - val_loss: 0.3793 - val_accuracy: 0.8350\n",
            "Epoch 30/150\n",
            "28/28 [==============================] - 25s 891ms/step - loss: 0.2416 - accuracy: 0.9040 - val_loss: 0.3355 - val_accuracy: 0.8688\n",
            "Epoch 31/150\n",
            "28/28 [==============================] - 25s 880ms/step - loss: 0.2253 - accuracy: 0.9163 - val_loss: 0.4338 - val_accuracy: 0.8091\n",
            "Epoch 32/150\n",
            "28/28 [==============================] - 25s 880ms/step - loss: 0.2352 - accuracy: 0.9107 - val_loss: 0.4089 - val_accuracy: 0.8370\n",
            "Epoch 33/150\n",
            "28/28 [==============================] - 25s 879ms/step - loss: 0.2413 - accuracy: 0.9007 - val_loss: 1.0401 - val_accuracy: 0.6501\n",
            "Epoch 34/150\n",
            "28/28 [==============================] - 25s 879ms/step - loss: 0.2616 - accuracy: 0.9007 - val_loss: 0.3396 - val_accuracy: 0.8509\n",
            "Epoch 35/150\n",
            "28/28 [==============================] - 25s 878ms/step - loss: 0.2382 - accuracy: 0.9051 - val_loss: 0.7706 - val_accuracy: 0.7972\n",
            "Epoch 36/150\n",
            "28/28 [==============================] - 26s 949ms/step - loss: 0.2271 - accuracy: 0.9208 - val_loss: 0.3493 - val_accuracy: 0.8728\n",
            "Epoch 37/150\n",
            "28/28 [==============================] - 25s 879ms/step - loss: 0.2470 - accuracy: 0.9029 - val_loss: 0.4975 - val_accuracy: 0.8529\n",
            "Epoch 38/150\n",
            "28/28 [==============================] - 25s 880ms/step - loss: 0.2460 - accuracy: 0.9029 - val_loss: 1.0260 - val_accuracy: 0.8091\n",
            "Epoch 39/150\n",
            "28/28 [==============================] - 25s 887ms/step - loss: 0.1997 - accuracy: 0.9263 - val_loss: 0.3774 - val_accuracy: 0.8787\n",
            "Epoch 40/150\n",
            "28/28 [==============================] - 25s 892ms/step - loss: 0.2255 - accuracy: 0.9107 - val_loss: 0.4427 - val_accuracy: 0.8728\n",
            "Epoch 41/150\n",
            "28/28 [==============================] - 25s 881ms/step - loss: 0.2143 - accuracy: 0.9141 - val_loss: 1.4414 - val_accuracy: 0.7197\n",
            "Epoch 42/150\n",
            "28/28 [==============================] - 25s 879ms/step - loss: 0.2084 - accuracy: 0.9230 - val_loss: 1.0993 - val_accuracy: 0.7634\n",
            "Epoch 43/150\n",
            "28/28 [==============================] - 25s 887ms/step - loss: 0.2161 - accuracy: 0.9129 - val_loss: 0.2627 - val_accuracy: 0.8966\n",
            "Epoch 44/150\n",
            "28/28 [==============================] - 25s 879ms/step - loss: 0.2123 - accuracy: 0.9141 - val_loss: 0.6176 - val_accuracy: 0.7336\n",
            "Epoch 45/150\n",
            "28/28 [==============================] - 25s 882ms/step - loss: 0.2084 - accuracy: 0.9152 - val_loss: 0.4491 - val_accuracy: 0.7773\n",
            "Epoch 46/150\n",
            "28/28 [==============================] - 25s 880ms/step - loss: 0.1966 - accuracy: 0.9118 - val_loss: 0.3654 - val_accuracy: 0.8628\n",
            "Epoch 47/150\n",
            "28/28 [==============================] - 25s 878ms/step - loss: 0.2113 - accuracy: 0.9152 - val_loss: 0.2887 - val_accuracy: 0.8807\n",
            "Epoch 48/150\n",
            "28/28 [==============================] - 25s 884ms/step - loss: 0.2027 - accuracy: 0.9141 - val_loss: 0.3432 - val_accuracy: 0.8608\n",
            "Epoch 49/150\n",
            "28/28 [==============================] - 25s 878ms/step - loss: 0.1889 - accuracy: 0.9297 - val_loss: 0.3528 - val_accuracy: 0.8708\n",
            "Epoch 50/150\n",
            "28/28 [==============================] - 25s 878ms/step - loss: 0.1743 - accuracy: 0.9230 - val_loss: 0.4668 - val_accuracy: 0.8449\n",
            "Epoch 51/150\n",
            "28/28 [==============================] - 25s 879ms/step - loss: 0.2474 - accuracy: 0.8984 - val_loss: 6.8727 - val_accuracy: 0.3817\n",
            "Epoch 52/150\n",
            "28/28 [==============================] - 25s 879ms/step - loss: 0.2141 - accuracy: 0.9185 - val_loss: 2.4383 - val_accuracy: 0.4513\n",
            "Epoch 53/150\n",
            "28/28 [==============================] - 25s 879ms/step - loss: 0.2106 - accuracy: 0.9208 - val_loss: 1.1826 - val_accuracy: 0.6958\n",
            "Epoch 54/150\n",
            "28/28 [==============================] - 25s 878ms/step - loss: 0.2050 - accuracy: 0.9196 - val_loss: 0.8222 - val_accuracy: 0.7078\n",
            "Epoch 55/150\n",
            "28/28 [==============================] - 25s 883ms/step - loss: 0.2154 - accuracy: 0.9263 - val_loss: 0.6600 - val_accuracy: 0.8052\n",
            "Epoch 56/150\n",
            "28/28 [==============================] - 25s 881ms/step - loss: 0.3960 - accuracy: 0.8772 - val_loss: 361824.7500 - val_accuracy: 0.6183\n",
            "Epoch 57/150\n",
            "28/28 [==============================] - 25s 879ms/step - loss: 0.3531 - accuracy: 0.8694 - val_loss: 45422.0586 - val_accuracy: 0.6183\n",
            "Epoch 58/150\n",
            "28/28 [==============================] - 25s 891ms/step - loss: 0.2801 - accuracy: 0.8906 - val_loss: 24592.6895 - val_accuracy: 0.6183\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_model_minor_minor.save('/content/drive/MyDrive/gp/Minor_Minor.h5')\n"
      ],
      "metadata": {
        "id": "GsjGK1gwq3cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction=_model_minor_minor.predict(testing_set)\n",
        "classes_x=np.argmax(prediction,axis=1)\n",
        "classes_x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7ZHJSXcq3Zr",
        "outputId": "cddb9c5f-b34d-4606-a302-124e90ced6df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0,\n",
              "       0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1,\n",
              "       1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0,\n",
              "       0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0,\n",
              "       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cf = confusion_matrix(y_true= true_labels, y_pred= classes_x)\n",
        "score = accuracy_score(y_true= true_labels, y_pred=classes_x)\n",
        "print(cf)\n",
        "print('the model performane is: ', score*100, \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyIg59NoqFbT",
        "outputId": "04dbeeb4-b7b3-41c5-e2a6-b0cd398aa888"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[96  9]\n",
            " [12 53]]\n",
            "the model performane is:  87.6470588235294 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(true_labels, classes_x,target_names=label_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_N11EsRUqJxL",
        "outputId": "4e1eb4a9-8d4d-4044-9328-5598fd0953b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    abnormal       0.89      0.91      0.90       105\n",
            "      normal       0.85      0.82      0.83        65\n",
            "\n",
            "    accuracy                           0.88       170\n",
            "   macro avg       0.87      0.86      0.87       170\n",
            "weighted avg       0.88      0.88      0.88       170\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(true_labels, classes_x,target_names=label_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IgVwiqZ_q3TN",
        "outputId": "c0d4ec41-3745-4d46-d2d2-9812c0424865"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    abnormal       0.97      0.88      0.92       393\n",
            "      normal       0.52      0.82      0.64        65\n",
            "\n",
            "    accuracy                           0.87       458\n",
            "   macro avg       0.75      0.85      0.78       458\n",
            "weighted avg       0.90      0.87      0.88       458\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# major-major\n",
        "726-726\\\n",
        "max no of row abnormal data"
      ],
      "metadata": {
        "id": "cuj5sZu6o4Tj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_generation = ImageDataGenerator(rescale=1./255)\n",
        "training_set = train_data_generation.flow_from_directory('/content/drive/MyDrive/gp/50:50/MAJOR-MAJOR/train',\n",
        "                                                         target_size=(224, 224),\n",
        "                                                         batch_size=32,\n",
        "                                                         class_mode='binary',seed=0)\n",
        "\n",
        "# preprocessing the testing set\n",
        "test_data_generation = ImageDataGenerator(rescale=1./255)\n",
        "testing_set = test_data_generation.flow_from_directory('/content/drive/MyDrive/gp/50:50/MAJOR-MAJOR/test',\n",
        "                                                       target_size=(224, 224),\n",
        "                                                       batch_size=32,\n",
        "                                                       class_mode='binary',seed=0)\n",
        "\n",
        "val_data_generation = ImageDataGenerator(rescale=1./255)\n",
        "val_set = test_data_generation.flow_from_directory('/content/drive/MyDrive/gp/50:50/MAJOR-MAJOR/val',\n",
        "                                                       target_size=(224, 224),\n",
        "                                                       batch_size=32,\n",
        "                                                       class_mode='binary',seed=0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a88aec4a-9948-49ec-fa4b-5a008a6765f0",
        "id": "Jk80iPEZo3Db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1452 images belonging to 2 classes.\n",
            "Found 170 images belonging to 2 classes.\n",
            "Found 503 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "true_labels=[]\n",
        "true_labels = np.concatenate([testing_set.next()[1] for i in range(testing_set.__len__())])\n",
        "true_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19e408d0-8d77-405a-c785-c614ef749075",
        "id": "IMBZTqe8p5BJ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1.,\n",
              "       0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1.,\n",
              "       1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1.,\n",
              "       0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1.,\n",
              "       1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
              "       1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1.,\n",
              "       0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1.],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_model_major_major= densenet([224,224,3],2)\n",
        "\n",
        "_model_major_major.compile(optimizer='adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "history_major_major=_model_major_major.fit(x=training_set, validation_data=val_set, epochs=150,callbacks=([early_s]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09107133-25b6-491d-f985-12215badc007",
        "id": "j6BGaqnYqiY6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "46/46 [==============================] - 63s 895ms/step - loss: 1.0009 - accuracy: 0.6405 - val_loss: 57.5779 - val_accuracy: 0.4831\n",
            "Epoch 2/150\n",
            "46/46 [==============================] - 38s 817ms/step - loss: 0.5717 - accuracy: 0.7300 - val_loss: 17.0171 - val_accuracy: 0.3817\n",
            "Epoch 3/150\n",
            "46/46 [==============================] - 38s 816ms/step - loss: 0.5883 - accuracy: 0.7273 - val_loss: 28.9122 - val_accuracy: 0.3917\n",
            "Epoch 4/150\n",
            "46/46 [==============================] - 38s 820ms/step - loss: 0.6183 - accuracy: 0.7211 - val_loss: 83.6447 - val_accuracy: 0.5189\n",
            "Epoch 5/150\n",
            "46/46 [==============================] - 38s 820ms/step - loss: 0.5643 - accuracy: 0.7541 - val_loss: 9.4629 - val_accuracy: 0.6083\n",
            "Epoch 6/150\n",
            "46/46 [==============================] - 38s 821ms/step - loss: 0.5713 - accuracy: 0.7459 - val_loss: 2.3617 - val_accuracy: 0.6123\n",
            "Epoch 7/150\n",
            "46/46 [==============================] - 37s 813ms/step - loss: 0.4920 - accuracy: 0.7734 - val_loss: 0.7460 - val_accuracy: 0.5765\n",
            "Epoch 8/150\n",
            "46/46 [==============================] - 38s 820ms/step - loss: 0.5109 - accuracy: 0.7707 - val_loss: 0.6251 - val_accuracy: 0.6620\n",
            "Epoch 9/150\n",
            "46/46 [==============================] - 38s 819ms/step - loss: 0.4970 - accuracy: 0.7762 - val_loss: 1.6691 - val_accuracy: 0.6660\n",
            "Epoch 10/150\n",
            "46/46 [==============================] - 38s 819ms/step - loss: 0.4893 - accuracy: 0.7789 - val_loss: 0.8833 - val_accuracy: 0.6859\n",
            "Epoch 11/150\n",
            "46/46 [==============================] - 38s 820ms/step - loss: 0.4531 - accuracy: 0.8037 - val_loss: 0.7210 - val_accuracy: 0.7157\n",
            "Epoch 12/150\n",
            "46/46 [==============================] - 38s 821ms/step - loss: 0.4578 - accuracy: 0.8030 - val_loss: 0.4825 - val_accuracy: 0.8250\n",
            "Epoch 13/150\n",
            "46/46 [==============================] - 38s 816ms/step - loss: 0.4433 - accuracy: 0.8140 - val_loss: 0.6893 - val_accuracy: 0.7237\n",
            "Epoch 14/150\n",
            "46/46 [==============================] - 38s 815ms/step - loss: 0.4353 - accuracy: 0.8168 - val_loss: 0.5610 - val_accuracy: 0.7455\n",
            "Epoch 15/150\n",
            "46/46 [==============================] - 38s 815ms/step - loss: 0.4270 - accuracy: 0.8134 - val_loss: 0.6413 - val_accuracy: 0.6083\n",
            "Epoch 16/150\n",
            "46/46 [==============================] - 38s 815ms/step - loss: 0.3978 - accuracy: 0.8340 - val_loss: 0.7585 - val_accuracy: 0.7256\n",
            "Epoch 17/150\n",
            "46/46 [==============================] - 38s 816ms/step - loss: 0.4300 - accuracy: 0.8140 - val_loss: 0.9255 - val_accuracy: 0.6322\n",
            "Epoch 18/150\n",
            "46/46 [==============================] - 38s 815ms/step - loss: 0.4023 - accuracy: 0.8202 - val_loss: 0.7575 - val_accuracy: 0.5626\n",
            "Epoch 19/150\n",
            "46/46 [==============================] - 38s 816ms/step - loss: 0.4207 - accuracy: 0.8223 - val_loss: 1.1363 - val_accuracy: 0.6382\n",
            "Epoch 20/150\n",
            "46/46 [==============================] - 38s 816ms/step - loss: 0.4051 - accuracy: 0.8306 - val_loss: 1.5146 - val_accuracy: 0.6879\n",
            "Epoch 21/150\n",
            "46/46 [==============================] - 38s 817ms/step - loss: 0.4067 - accuracy: 0.8251 - val_loss: 1.4807 - val_accuracy: 0.4771\n",
            "Epoch 22/150\n",
            "46/46 [==============================] - 37s 814ms/step - loss: 0.4127 - accuracy: 0.8271 - val_loss: 0.9382 - val_accuracy: 0.6163\n",
            "Epoch 23/150\n",
            "46/46 [==============================] - 37s 814ms/step - loss: 0.3843 - accuracy: 0.8306 - val_loss: 0.6613 - val_accuracy: 0.8111\n",
            "Epoch 24/150\n",
            "46/46 [==============================] - 37s 814ms/step - loss: 0.3815 - accuracy: 0.8320 - val_loss: 0.4685 - val_accuracy: 0.7833\n",
            "Epoch 25/150\n",
            "46/46 [==============================] - 38s 820ms/step - loss: 0.3889 - accuracy: 0.8402 - val_loss: 0.3878 - val_accuracy: 0.8370\n",
            "Epoch 26/150\n",
            "46/46 [==============================] - 38s 815ms/step - loss: 0.3960 - accuracy: 0.8182 - val_loss: 0.5155 - val_accuracy: 0.7773\n",
            "Epoch 27/150\n",
            "46/46 [==============================] - 38s 816ms/step - loss: 0.3733 - accuracy: 0.8485 - val_loss: 0.3713 - val_accuracy: 0.8330\n",
            "Epoch 28/150\n",
            "46/46 [==============================] - 38s 816ms/step - loss: 0.3822 - accuracy: 0.8368 - val_loss: 0.3665 - val_accuracy: 0.8310\n",
            "Epoch 29/150\n",
            "46/46 [==============================] - 38s 830ms/step - loss: 0.3483 - accuracy: 0.8512 - val_loss: 0.4239 - val_accuracy: 0.8509\n",
            "Epoch 30/150\n",
            "46/46 [==============================] - 38s 816ms/step - loss: 0.3559 - accuracy: 0.8609 - val_loss: 0.5540 - val_accuracy: 0.7356\n",
            "Epoch 31/150\n",
            "46/46 [==============================] - 37s 814ms/step - loss: 0.3762 - accuracy: 0.8368 - val_loss: 0.9403 - val_accuracy: 0.7237\n",
            "Epoch 32/150\n",
            "46/46 [==============================] - 38s 816ms/step - loss: 0.3570 - accuracy: 0.8471 - val_loss: 0.4870 - val_accuracy: 0.7177\n",
            "Epoch 33/150\n",
            "46/46 [==============================] - 38s 821ms/step - loss: 0.3501 - accuracy: 0.8526 - val_loss: 0.4854 - val_accuracy: 0.8529\n",
            "Epoch 34/150\n",
            "46/46 [==============================] - 38s 815ms/step - loss: 0.3559 - accuracy: 0.8595 - val_loss: 0.5273 - val_accuracy: 0.7634\n",
            "Epoch 35/150\n",
            "46/46 [==============================] - 38s 815ms/step - loss: 0.3416 - accuracy: 0.8588 - val_loss: 0.3860 - val_accuracy: 0.8310\n",
            "Epoch 36/150\n",
            "46/46 [==============================] - 38s 816ms/step - loss: 0.3500 - accuracy: 0.8526 - val_loss: 0.4610 - val_accuracy: 0.8429\n",
            "Epoch 37/150\n",
            "46/46 [==============================] - 37s 815ms/step - loss: 0.3102 - accuracy: 0.8643 - val_loss: 0.8811 - val_accuracy: 0.7177\n",
            "Epoch 38/150\n",
            "46/46 [==============================] - 38s 817ms/step - loss: 0.3149 - accuracy: 0.8664 - val_loss: 1.3980 - val_accuracy: 0.5089\n",
            "Epoch 39/150\n",
            "46/46 [==============================] - 38s 815ms/step - loss: 0.3194 - accuracy: 0.8691 - val_loss: 0.8504 - val_accuracy: 0.6799\n",
            "Epoch 40/150\n",
            "46/46 [==============================] - 38s 820ms/step - loss: 0.3186 - accuracy: 0.8588 - val_loss: 0.2948 - val_accuracy: 0.8966\n",
            "Epoch 41/150\n",
            "46/46 [==============================] - 38s 816ms/step - loss: 0.3219 - accuracy: 0.8595 - val_loss: 0.6702 - val_accuracy: 0.7575\n",
            "Epoch 42/150\n",
            "46/46 [==============================] - 38s 815ms/step - loss: 0.3120 - accuracy: 0.8712 - val_loss: 0.6995 - val_accuracy: 0.7455\n",
            "Epoch 43/150\n",
            "46/46 [==============================] - 38s 816ms/step - loss: 0.3215 - accuracy: 0.8650 - val_loss: 0.3578 - val_accuracy: 0.8310\n",
            "Epoch 44/150\n",
            "46/46 [==============================] - 38s 817ms/step - loss: 0.3164 - accuracy: 0.8588 - val_loss: 0.3853 - val_accuracy: 0.8509\n",
            "Epoch 45/150\n",
            "46/46 [==============================] - 38s 815ms/step - loss: 0.3057 - accuracy: 0.8747 - val_loss: 0.5748 - val_accuracy: 0.7654\n",
            "Epoch 46/150\n",
            "46/46 [==============================] - 38s 816ms/step - loss: 0.3031 - accuracy: 0.8705 - val_loss: 0.4422 - val_accuracy: 0.7734\n",
            "Epoch 47/150\n",
            "46/46 [==============================] - 37s 815ms/step - loss: 0.2619 - accuracy: 0.8815 - val_loss: 0.6585 - val_accuracy: 0.6958\n",
            "Epoch 48/150\n",
            "46/46 [==============================] - 38s 816ms/step - loss: 0.3021 - accuracy: 0.8726 - val_loss: 1.8536 - val_accuracy: 0.4394\n",
            "Epoch 49/150\n",
            "46/46 [==============================] - 38s 815ms/step - loss: 0.2970 - accuracy: 0.8774 - val_loss: 1.1255 - val_accuracy: 0.5447\n",
            "Epoch 50/150\n",
            "46/46 [==============================] - 38s 815ms/step - loss: 0.2713 - accuracy: 0.8850 - val_loss: 0.6214 - val_accuracy: 0.7356\n",
            "Epoch 51/150\n",
            "46/46 [==============================] - 38s 815ms/step - loss: 0.2888 - accuracy: 0.8636 - val_loss: 2.3232 - val_accuracy: 0.4573\n",
            "Epoch 52/150\n",
            "46/46 [==============================] - 38s 816ms/step - loss: 0.2929 - accuracy: 0.8747 - val_loss: 0.7202 - val_accuracy: 0.6481\n",
            "Epoch 53/150\n",
            "46/46 [==============================] - 38s 816ms/step - loss: 0.2605 - accuracy: 0.8953 - val_loss: 0.5811 - val_accuracy: 0.7197\n",
            "Epoch 54/150\n",
            "46/46 [==============================] - 38s 816ms/step - loss: 0.2855 - accuracy: 0.8822 - val_loss: 1.0125 - val_accuracy: 0.6740\n",
            "Epoch 55/150\n",
            "46/46 [==============================] - 38s 822ms/step - loss: 0.2649 - accuracy: 0.8891 - val_loss: 0.6562 - val_accuracy: 0.7038\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_model_major_major.save('/content/drive/MyDrive/gp/Major_Major.h5')\n"
      ],
      "metadata": {
        "id": "pPfSVz7vpC1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_model_major_major.save('/content/drive/MyDrive/gp/Major_Major2.h5')\n"
      ],
      "metadata": {
        "id": "IaWrAzsS6Rp3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction=_model_major_major.predict(testing_set)\n",
        "classes_x=np.argmax(prediction,axis=1)\n",
        "classes_x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e4d7800-f165-4160-a630-95cd06336194",
        "id": "6m84nbRUrt9Y"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
              "       0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1,\n",
              "       0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
              "       1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1,\n",
              "       0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1,\n",
              "       1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cf = confusion_matrix(y_true= true_labels, y_pred= classes_x)\n",
        "score = accuracy_score(y_true= true_labels, y_pred=classes_x)\n",
        "print(cf)\n",
        "print('the model performane is: ', score*100, \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d786a0d-eed4-4231-8475-3bd76d6bc003",
        "id": "YW1ETIMbr2I8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[57 48]\n",
            " [45 20]]\n",
            "the model performane is:  45.294117647058826 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(true_labels, classes_x,target_names=label_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXxGO7vCoiHV",
        "outputId": "7b238719-1eea-48c0-c35d-ddf29a9edfdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    abnormal       0.56      0.54      0.55       105\n",
            "      normal       0.29      0.31      0.30        65\n",
            "\n",
            "    accuracy                           0.45       170\n",
            "   macro avg       0.43      0.43      0.43       170\n",
            "weighted avg       0.46      0.45      0.46       170\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "hstjEp87o0hb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#pretrained"
      ],
      "metadata": {
        "id": "G2GRrLtbbV6J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocessing the training set\n",
        "train_data_generation = ImageDataGenerator(rescale=1./255)\n",
        "training_set = train_data_generation.flow_from_directory('/content/drive/MyDrive/gp/Splitted/train',\n",
        "                                                         target_size=(224, 224),\n",
        "                                                         batch_size=32,\n",
        "                                                         class_mode='binary',seed=0)\n",
        "\n",
        "# preprocessing the valid set\n",
        "valid_data_generation = ImageDataGenerator(rescale=1./255)\n",
        "validing_set = valid_data_generation.flow_from_directory('/content/drive/MyDrive/gp/Splitted/val',\n",
        "                                                       target_size=(224, 224),\n",
        "                                                       batch_size=32,\n",
        "                                                       class_mode='binary',seed=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bsICeHR0Xo_",
        "outputId": "d3a88e49-f2cc-4baf-eb12-48ef7cad7704"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1174 images belonging to 2 classes.\n",
            "Found 503 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data_generation = ImageDataGenerator(rescale=1./255)\n",
        "testing_set = test_data_generation.flow_from_directory('/content/drive/MyDrive/gp/Splitted/test',\n",
        "                                                       target_size=(224, 224),\n",
        "                                                       batch_size=32,\n",
        "                                                       class_mode='binary',seed=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duoyNGAs5_Ur",
        "outputId": "f0004289-79b9-4700-f426-4ad6b9caf32e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 170 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size =32\n",
        "X_test, y_test = next(testing_set)\n",
        "for i in range(int(len(testing_set)/batch_size)-1): #1st batch is already fetched before the for loop.\n",
        "    img , label = next(testing_set)\n",
        "    X_test = np.append(X_test, img, axis=0 )\n",
        "    y_test = np.append(y_test, label, axis=0)\n",
        "\n",
        "print(X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2maU78L3UG0w",
        "outputId": "bf52abc1-4f22-4708-cd15-c7502f051df5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 224, 224, 3) (32,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.image import imread\n",
        "print(y_test[2])\n",
        "plt.imshow(X_test[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "njv2EdRsUWKM",
        "outputId": "4e9c4b4b-91fa-43e2-e7de-de97b84c7c4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f6895658b50>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "label_names =['abnormal','normal']"
      ],
      "metadata": {
        "id": "WSukDH34Ujse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true_labels = np.concatenate([testing_set.next()[1] for i in range(testing_set.__len__())])\n",
        "true_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5U3DMztg5_Rh",
        "outputId": "2440a84d-28f9-4d0c-bb54-5461362c7c27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
              "       1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1.,\n",
              "       1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1.,\n",
              "       1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1.,\n",
              "       0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
              "       0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1.],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# keras with last layer replaced"
      ],
      "metadata": {
        "id": "qjcJIxqd7DyA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=tf.keras.applications.DenseNet121(include_top=True,\n",
        "    weights=None,\n",
        "    input_tensor=None,\n",
        "    input_shape=(224, 224, 3),\n",
        "    pooling='max',\n",
        "    classes=2)\n",
        "base_inputs = model.layers[0].input\n",
        "base_output = model.layers[-2].output\n",
        "output = layers.Dense(2,activation='sigmoid')(base_output)\n",
        "model = keras.Model(base_inputs, output)\n",
        "print(\"densenet\",model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqWZTGHl1d7_",
        "outputId": "642919a3-6b28-4557-c0d7-3a89a4958e91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " zero_padding2d (ZeroPadding2D)  (None, 230, 230, 3)  0          ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv1/conv (Conv2D)            (None, 112, 112, 64  9408        ['zero_padding2d[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1/bn (BatchNormalization)  (None, 112, 112, 64  256         ['conv1/conv[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1/relu (Activation)        (None, 112, 112, 64  0           ['conv1/bn[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " zero_padding2d_1 (ZeroPadding2  (None, 114, 114, 64  0          ['conv1/relu[0][0]']             \n",
            " D)                             )                                                                 \n",
            "                                                                                                  \n",
            " pool1 (MaxPooling2D)           (None, 56, 56, 64)   0           ['zero_padding2d_1[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block1_0_bn (BatchNormal  (None, 56, 56, 64)  256         ['pool1[0][0]']                  \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_0_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 128)  8192        ['conv2_block1_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_concat (Concatena  (None, 56, 56, 96)  0           ['pool1[0][0]',                  \n",
            " te)                                                              'conv2_block1_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_0_bn (BatchNormal  (None, 56, 56, 96)  384         ['conv2_block1_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_0_relu (Activatio  (None, 56, 56, 96)  0           ['conv2_block2_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 128)  12288       ['conv2_block2_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_concat (Concatena  (None, 56, 56, 128)  0          ['conv2_block1_concat[0][0]',    \n",
            " te)                                                              'conv2_block2_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_0_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block2_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_0_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block3_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 128)  16384       ['conv2_block3_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_concat (Concatena  (None, 56, 56, 160)  0          ['conv2_block2_concat[0][0]',    \n",
            " te)                                                              'conv2_block3_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block4_0_bn (BatchNormal  (None, 56, 56, 160)  640        ['conv2_block3_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block4_0_relu (Activatio  (None, 56, 56, 160)  0          ['conv2_block4_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block4_1_conv (Conv2D)   (None, 56, 56, 128)  20480       ['conv2_block4_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block4_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block4_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block4_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block4_concat (Concatena  (None, 56, 56, 192)  0          ['conv2_block3_concat[0][0]',    \n",
            " te)                                                              'conv2_block4_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block5_0_bn (BatchNormal  (None, 56, 56, 192)  768        ['conv2_block4_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block5_0_relu (Activatio  (None, 56, 56, 192)  0          ['conv2_block5_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block5_1_conv (Conv2D)   (None, 56, 56, 128)  24576       ['conv2_block5_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block5_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block5_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block5_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block5_concat (Concatena  (None, 56, 56, 224)  0          ['conv2_block4_concat[0][0]',    \n",
            " te)                                                              'conv2_block5_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block6_0_bn (BatchNormal  (None, 56, 56, 224)  896        ['conv2_block5_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block6_0_relu (Activatio  (None, 56, 56, 224)  0          ['conv2_block6_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block6_1_conv (Conv2D)   (None, 56, 56, 128)  28672       ['conv2_block6_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block6_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block6_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block6_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block6_concat (Concatena  (None, 56, 56, 256)  0          ['conv2_block5_concat[0][0]',    \n",
            " te)                                                              'conv2_block6_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " pool2_bn (BatchNormalization)  (None, 56, 56, 256)  1024        ['conv2_block6_concat[0][0]']    \n",
            "                                                                                                  \n",
            " pool2_relu (Activation)        (None, 56, 56, 256)  0           ['pool2_bn[0][0]']               \n",
            "                                                                                                  \n",
            " pool2_conv (Conv2D)            (None, 56, 56, 128)  32768       ['pool2_relu[0][0]']             \n",
            "                                                                                                  \n",
            " pool2_pool (AveragePooling2D)  (None, 28, 28, 128)  0           ['pool2_conv[0][0]']             \n",
            "                                                                                                  \n",
            " conv3_block1_0_bn (BatchNormal  (None, 28, 28, 128)  512        ['pool2_pool[0][0]']             \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_0_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  16384       ['conv3_block1_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_concat (Concatena  (None, 28, 28, 160)  0          ['pool2_pool[0][0]',             \n",
            " te)                                                              'conv3_block1_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_0_bn (BatchNormal  (None, 28, 28, 160)  640        ['conv3_block1_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_0_relu (Activatio  (None, 28, 28, 160)  0          ['conv3_block2_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  20480       ['conv3_block2_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_concat (Concatena  (None, 28, 28, 192)  0          ['conv3_block1_concat[0][0]',    \n",
            " te)                                                              'conv3_block2_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_0_bn (BatchNormal  (None, 28, 28, 192)  768        ['conv3_block2_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_0_relu (Activatio  (None, 28, 28, 192)  0          ['conv3_block3_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  24576       ['conv3_block3_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_concat (Concatena  (None, 28, 28, 224)  0          ['conv3_block2_concat[0][0]',    \n",
            " te)                                                              'conv3_block3_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_0_bn (BatchNormal  (None, 28, 28, 224)  896        ['conv3_block3_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_0_relu (Activatio  (None, 28, 28, 224)  0          ['conv3_block4_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  28672       ['conv3_block4_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_concat (Concatena  (None, 28, 28, 256)  0          ['conv3_block3_concat[0][0]',    \n",
            " te)                                                              'conv3_block4_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block5_0_bn (BatchNormal  (None, 28, 28, 256)  1024       ['conv3_block4_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block5_0_relu (Activatio  (None, 28, 28, 256)  0          ['conv3_block5_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block5_1_conv (Conv2D)   (None, 28, 28, 128)  32768       ['conv3_block5_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block5_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block5_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block5_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block5_concat (Concatena  (None, 28, 28, 288)  0          ['conv3_block4_concat[0][0]',    \n",
            " te)                                                              'conv3_block5_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block6_0_bn (BatchNormal  (None, 28, 28, 288)  1152       ['conv3_block5_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block6_0_relu (Activatio  (None, 28, 28, 288)  0          ['conv3_block6_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block6_1_conv (Conv2D)   (None, 28, 28, 128)  36864       ['conv3_block6_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block6_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block6_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block6_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block6_concat (Concatena  (None, 28, 28, 320)  0          ['conv3_block5_concat[0][0]',    \n",
            " te)                                                              'conv3_block6_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block7_0_bn (BatchNormal  (None, 28, 28, 320)  1280       ['conv3_block6_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block7_0_relu (Activatio  (None, 28, 28, 320)  0          ['conv3_block7_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block7_1_conv (Conv2D)   (None, 28, 28, 128)  40960       ['conv3_block7_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block7_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block7_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block7_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block7_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block7_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block7_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block7_concat (Concatena  (None, 28, 28, 352)  0          ['conv3_block6_concat[0][0]',    \n",
            " te)                                                              'conv3_block7_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block8_0_bn (BatchNormal  (None, 28, 28, 352)  1408       ['conv3_block7_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block8_0_relu (Activatio  (None, 28, 28, 352)  0          ['conv3_block8_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block8_1_conv (Conv2D)   (None, 28, 28, 128)  45056       ['conv3_block8_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block8_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block8_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block8_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block8_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block8_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block8_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block8_concat (Concatena  (None, 28, 28, 384)  0          ['conv3_block7_concat[0][0]',    \n",
            " te)                                                              'conv3_block8_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block9_0_bn (BatchNormal  (None, 28, 28, 384)  1536       ['conv3_block8_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block9_0_relu (Activatio  (None, 28, 28, 384)  0          ['conv3_block9_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block9_1_conv (Conv2D)   (None, 28, 28, 128)  49152       ['conv3_block9_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block9_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block9_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block9_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block9_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block9_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block9_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block9_concat (Concatena  (None, 28, 28, 416)  0          ['conv3_block8_concat[0][0]',    \n",
            " te)                                                              'conv3_block9_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block10_0_bn (BatchNorma  (None, 28, 28, 416)  1664       ['conv3_block9_concat[0][0]']    \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block10_0_relu (Activati  (None, 28, 28, 416)  0          ['conv3_block10_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block10_1_conv (Conv2D)  (None, 28, 28, 128)  53248       ['conv3_block10_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block10_1_bn (BatchNorma  (None, 28, 28, 128)  512        ['conv3_block10_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block10_1_relu (Activati  (None, 28, 28, 128)  0          ['conv3_block10_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block10_2_conv (Conv2D)  (None, 28, 28, 32)   36864       ['conv3_block10_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block10_concat (Concaten  (None, 28, 28, 448)  0          ['conv3_block9_concat[0][0]',    \n",
            " ate)                                                             'conv3_block10_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block11_0_bn (BatchNorma  (None, 28, 28, 448)  1792       ['conv3_block10_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block11_0_relu (Activati  (None, 28, 28, 448)  0          ['conv3_block11_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block11_1_conv (Conv2D)  (None, 28, 28, 128)  57344       ['conv3_block11_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block11_1_bn (BatchNorma  (None, 28, 28, 128)  512        ['conv3_block11_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block11_1_relu (Activati  (None, 28, 28, 128)  0          ['conv3_block11_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block11_2_conv (Conv2D)  (None, 28, 28, 32)   36864       ['conv3_block11_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block11_concat (Concaten  (None, 28, 28, 480)  0          ['conv3_block10_concat[0][0]',   \n",
            " ate)                                                             'conv3_block11_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block12_0_bn (BatchNorma  (None, 28, 28, 480)  1920       ['conv3_block11_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block12_0_relu (Activati  (None, 28, 28, 480)  0          ['conv3_block12_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block12_1_conv (Conv2D)  (None, 28, 28, 128)  61440       ['conv3_block12_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block12_1_bn (BatchNorma  (None, 28, 28, 128)  512        ['conv3_block12_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block12_1_relu (Activati  (None, 28, 28, 128)  0          ['conv3_block12_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block12_2_conv (Conv2D)  (None, 28, 28, 32)   36864       ['conv3_block12_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block12_concat (Concaten  (None, 28, 28, 512)  0          ['conv3_block11_concat[0][0]',   \n",
            " ate)                                                             'conv3_block12_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " pool3_bn (BatchNormalization)  (None, 28, 28, 512)  2048        ['conv3_block12_concat[0][0]']   \n",
            "                                                                                                  \n",
            " pool3_relu (Activation)        (None, 28, 28, 512)  0           ['pool3_bn[0][0]']               \n",
            "                                                                                                  \n",
            " pool3_conv (Conv2D)            (None, 28, 28, 256)  131072      ['pool3_relu[0][0]']             \n",
            "                                                                                                  \n",
            " pool3_pool (AveragePooling2D)  (None, 14, 14, 256)  0           ['pool3_conv[0][0]']             \n",
            "                                                                                                  \n",
            " conv4_block1_0_bn (BatchNormal  (None, 14, 14, 256)  1024       ['pool3_pool[0][0]']             \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_0_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 128)  32768       ['conv4_block1_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_concat (Concatena  (None, 14, 14, 288)  0          ['pool3_pool[0][0]',             \n",
            " te)                                                              'conv4_block1_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_0_bn (BatchNormal  (None, 14, 14, 288)  1152       ['conv4_block1_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_0_relu (Activatio  (None, 14, 14, 288)  0          ['conv4_block2_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 128)  36864       ['conv4_block2_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_concat (Concatena  (None, 14, 14, 320)  0          ['conv4_block1_concat[0][0]',    \n",
            " te)                                                              'conv4_block2_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_0_bn (BatchNormal  (None, 14, 14, 320)  1280       ['conv4_block2_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_0_relu (Activatio  (None, 14, 14, 320)  0          ['conv4_block3_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 128)  40960       ['conv4_block3_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_concat (Concatena  (None, 14, 14, 352)  0          ['conv4_block2_concat[0][0]',    \n",
            " te)                                                              'conv4_block3_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_0_bn (BatchNormal  (None, 14, 14, 352)  1408       ['conv4_block3_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_0_relu (Activatio  (None, 14, 14, 352)  0          ['conv4_block4_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 128)  45056       ['conv4_block4_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_concat (Concatena  (None, 14, 14, 384)  0          ['conv4_block3_concat[0][0]',    \n",
            " te)                                                              'conv4_block4_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_0_bn (BatchNormal  (None, 14, 14, 384)  1536       ['conv4_block4_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_0_relu (Activatio  (None, 14, 14, 384)  0          ['conv4_block5_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 128)  49152       ['conv4_block5_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_concat (Concatena  (None, 14, 14, 416)  0          ['conv4_block4_concat[0][0]',    \n",
            " te)                                                              'conv4_block5_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_0_bn (BatchNormal  (None, 14, 14, 416)  1664       ['conv4_block5_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_0_relu (Activatio  (None, 14, 14, 416)  0          ['conv4_block6_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 128)  53248       ['conv4_block6_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_concat (Concatena  (None, 14, 14, 448)  0          ['conv4_block5_concat[0][0]',    \n",
            " te)                                                              'conv4_block6_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block7_0_bn (BatchNormal  (None, 14, 14, 448)  1792       ['conv4_block6_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block7_0_relu (Activatio  (None, 14, 14, 448)  0          ['conv4_block7_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block7_1_conv (Conv2D)   (None, 14, 14, 128)  57344       ['conv4_block7_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block7_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block7_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block7_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block7_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block7_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block7_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block7_concat (Concatena  (None, 14, 14, 480)  0          ['conv4_block6_concat[0][0]',    \n",
            " te)                                                              'conv4_block7_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block8_0_bn (BatchNormal  (None, 14, 14, 480)  1920       ['conv4_block7_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block8_0_relu (Activatio  (None, 14, 14, 480)  0          ['conv4_block8_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block8_1_conv (Conv2D)   (None, 14, 14, 128)  61440       ['conv4_block8_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block8_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block8_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block8_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block8_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block8_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block8_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block8_concat (Concatena  (None, 14, 14, 512)  0          ['conv4_block7_concat[0][0]',    \n",
            " te)                                                              'conv4_block8_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block9_0_bn (BatchNormal  (None, 14, 14, 512)  2048       ['conv4_block8_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block9_0_relu (Activatio  (None, 14, 14, 512)  0          ['conv4_block9_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block9_1_conv (Conv2D)   (None, 14, 14, 128)  65536       ['conv4_block9_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block9_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block9_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block9_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block9_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block9_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block9_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block9_concat (Concatena  (None, 14, 14, 544)  0          ['conv4_block8_concat[0][0]',    \n",
            " te)                                                              'conv4_block9_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block10_0_bn (BatchNorma  (None, 14, 14, 544)  2176       ['conv4_block9_concat[0][0]']    \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block10_0_relu (Activati  (None, 14, 14, 544)  0          ['conv4_block10_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block10_1_conv (Conv2D)  (None, 14, 14, 128)  69632       ['conv4_block10_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block10_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block10_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block10_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block10_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block10_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block10_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block10_concat (Concaten  (None, 14, 14, 576)  0          ['conv4_block9_concat[0][0]',    \n",
            " ate)                                                             'conv4_block10_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block11_0_bn (BatchNorma  (None, 14, 14, 576)  2304       ['conv4_block10_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block11_0_relu (Activati  (None, 14, 14, 576)  0          ['conv4_block11_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block11_1_conv (Conv2D)  (None, 14, 14, 128)  73728       ['conv4_block11_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block11_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block11_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block11_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block11_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block11_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block11_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block11_concat (Concaten  (None, 14, 14, 608)  0          ['conv4_block10_concat[0][0]',   \n",
            " ate)                                                             'conv4_block11_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block12_0_bn (BatchNorma  (None, 14, 14, 608)  2432       ['conv4_block11_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block12_0_relu (Activati  (None, 14, 14, 608)  0          ['conv4_block12_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block12_1_conv (Conv2D)  (None, 14, 14, 128)  77824       ['conv4_block12_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block12_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block12_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block12_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block12_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block12_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block12_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block12_concat (Concaten  (None, 14, 14, 640)  0          ['conv4_block11_concat[0][0]',   \n",
            " ate)                                                             'conv4_block12_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block13_0_bn (BatchNorma  (None, 14, 14, 640)  2560       ['conv4_block12_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block13_0_relu (Activati  (None, 14, 14, 640)  0          ['conv4_block13_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block13_1_conv (Conv2D)  (None, 14, 14, 128)  81920       ['conv4_block13_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block13_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block13_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block13_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block13_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block13_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block13_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block13_concat (Concaten  (None, 14, 14, 672)  0          ['conv4_block12_concat[0][0]',   \n",
            " ate)                                                             'conv4_block13_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block14_0_bn (BatchNorma  (None, 14, 14, 672)  2688       ['conv4_block13_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block14_0_relu (Activati  (None, 14, 14, 672)  0          ['conv4_block14_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block14_1_conv (Conv2D)  (None, 14, 14, 128)  86016       ['conv4_block14_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block14_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block14_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block14_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block14_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block14_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block14_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block14_concat (Concaten  (None, 14, 14, 704)  0          ['conv4_block13_concat[0][0]',   \n",
            " ate)                                                             'conv4_block14_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block15_0_bn (BatchNorma  (None, 14, 14, 704)  2816       ['conv4_block14_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block15_0_relu (Activati  (None, 14, 14, 704)  0          ['conv4_block15_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block15_1_conv (Conv2D)  (None, 14, 14, 128)  90112       ['conv4_block15_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block15_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block15_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block15_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block15_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block15_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block15_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block15_concat (Concaten  (None, 14, 14, 736)  0          ['conv4_block14_concat[0][0]',   \n",
            " ate)                                                             'conv4_block15_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block16_0_bn (BatchNorma  (None, 14, 14, 736)  2944       ['conv4_block15_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block16_0_relu (Activati  (None, 14, 14, 736)  0          ['conv4_block16_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block16_1_conv (Conv2D)  (None, 14, 14, 128)  94208       ['conv4_block16_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block16_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block16_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block16_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block16_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block16_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block16_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block16_concat (Concaten  (None, 14, 14, 768)  0          ['conv4_block15_concat[0][0]',   \n",
            " ate)                                                             'conv4_block16_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block17_0_bn (BatchNorma  (None, 14, 14, 768)  3072       ['conv4_block16_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block17_0_relu (Activati  (None, 14, 14, 768)  0          ['conv4_block17_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block17_1_conv (Conv2D)  (None, 14, 14, 128)  98304       ['conv4_block17_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block17_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block17_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block17_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block17_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block17_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block17_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block17_concat (Concaten  (None, 14, 14, 800)  0          ['conv4_block16_concat[0][0]',   \n",
            " ate)                                                             'conv4_block17_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block18_0_bn (BatchNorma  (None, 14, 14, 800)  3200       ['conv4_block17_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block18_0_relu (Activati  (None, 14, 14, 800)  0          ['conv4_block18_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block18_1_conv (Conv2D)  (None, 14, 14, 128)  102400      ['conv4_block18_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block18_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block18_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block18_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block18_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block18_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block18_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block18_concat (Concaten  (None, 14, 14, 832)  0          ['conv4_block17_concat[0][0]',   \n",
            " ate)                                                             'conv4_block18_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block19_0_bn (BatchNorma  (None, 14, 14, 832)  3328       ['conv4_block18_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block19_0_relu (Activati  (None, 14, 14, 832)  0          ['conv4_block19_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block19_1_conv (Conv2D)  (None, 14, 14, 128)  106496      ['conv4_block19_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block19_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block19_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block19_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block19_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block19_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block19_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block19_concat (Concaten  (None, 14, 14, 864)  0          ['conv4_block18_concat[0][0]',   \n",
            " ate)                                                             'conv4_block19_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block20_0_bn (BatchNorma  (None, 14, 14, 864)  3456       ['conv4_block19_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block20_0_relu (Activati  (None, 14, 14, 864)  0          ['conv4_block20_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block20_1_conv (Conv2D)  (None, 14, 14, 128)  110592      ['conv4_block20_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block20_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block20_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block20_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block20_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block20_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block20_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block20_concat (Concaten  (None, 14, 14, 896)  0          ['conv4_block19_concat[0][0]',   \n",
            " ate)                                                             'conv4_block20_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block21_0_bn (BatchNorma  (None, 14, 14, 896)  3584       ['conv4_block20_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block21_0_relu (Activati  (None, 14, 14, 896)  0          ['conv4_block21_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block21_1_conv (Conv2D)  (None, 14, 14, 128)  114688      ['conv4_block21_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block21_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block21_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block21_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block21_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block21_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block21_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block21_concat (Concaten  (None, 14, 14, 928)  0          ['conv4_block20_concat[0][0]',   \n",
            " ate)                                                             'conv4_block21_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block22_0_bn (BatchNorma  (None, 14, 14, 928)  3712       ['conv4_block21_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block22_0_relu (Activati  (None, 14, 14, 928)  0          ['conv4_block22_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block22_1_conv (Conv2D)  (None, 14, 14, 128)  118784      ['conv4_block22_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block22_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block22_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block22_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block22_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block22_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block22_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block22_concat (Concaten  (None, 14, 14, 960)  0          ['conv4_block21_concat[0][0]',   \n",
            " ate)                                                             'conv4_block22_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block23_0_bn (BatchNorma  (None, 14, 14, 960)  3840       ['conv4_block22_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block23_0_relu (Activati  (None, 14, 14, 960)  0          ['conv4_block23_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block23_1_conv (Conv2D)  (None, 14, 14, 128)  122880      ['conv4_block23_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block23_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block23_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block23_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block23_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block23_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block23_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block23_concat (Concaten  (None, 14, 14, 992)  0          ['conv4_block22_concat[0][0]',   \n",
            " ate)                                                             'conv4_block23_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block24_0_bn (BatchNorma  (None, 14, 14, 992)  3968       ['conv4_block23_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block24_0_relu (Activati  (None, 14, 14, 992)  0          ['conv4_block24_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block24_1_conv (Conv2D)  (None, 14, 14, 128)  126976      ['conv4_block24_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block24_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block24_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block24_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block24_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block24_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block24_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block24_concat (Concaten  (None, 14, 14, 1024  0          ['conv4_block23_concat[0][0]',   \n",
            " ate)                           )                                 'conv4_block24_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " pool4_bn (BatchNormalization)  (None, 14, 14, 1024  4096        ['conv4_block24_concat[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool4_relu (Activation)        (None, 14, 14, 1024  0           ['pool4_bn[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool4_conv (Conv2D)            (None, 14, 14, 512)  524288      ['pool4_relu[0][0]']             \n",
            "                                                                                                  \n",
            " pool4_pool (AveragePooling2D)  (None, 7, 7, 512)    0           ['pool4_conv[0][0]']             \n",
            "                                                                                                  \n",
            " conv5_block1_0_bn (BatchNormal  (None, 7, 7, 512)   2048        ['pool4_pool[0][0]']             \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_0_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 128)    65536       ['conv5_block1_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_concat (Concatena  (None, 7, 7, 544)   0           ['pool4_pool[0][0]',             \n",
            " te)                                                              'conv5_block1_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_0_bn (BatchNormal  (None, 7, 7, 544)   2176        ['conv5_block1_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_0_relu (Activatio  (None, 7, 7, 544)   0           ['conv5_block2_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 128)    69632       ['conv5_block2_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_concat (Concatena  (None, 7, 7, 576)   0           ['conv5_block1_concat[0][0]',    \n",
            " te)                                                              'conv5_block2_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_0_bn (BatchNormal  (None, 7, 7, 576)   2304        ['conv5_block2_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_0_relu (Activatio  (None, 7, 7, 576)   0           ['conv5_block3_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 128)    73728       ['conv5_block3_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_concat (Concatena  (None, 7, 7, 608)   0           ['conv5_block2_concat[0][0]',    \n",
            " te)                                                              'conv5_block3_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block4_0_bn (BatchNormal  (None, 7, 7, 608)   2432        ['conv5_block3_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block4_0_relu (Activatio  (None, 7, 7, 608)   0           ['conv5_block4_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block4_1_conv (Conv2D)   (None, 7, 7, 128)    77824       ['conv5_block4_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block4_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block4_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block4_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block4_concat (Concatena  (None, 7, 7, 640)   0           ['conv5_block3_concat[0][0]',    \n",
            " te)                                                              'conv5_block4_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block5_0_bn (BatchNormal  (None, 7, 7, 640)   2560        ['conv5_block4_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block5_0_relu (Activatio  (None, 7, 7, 640)   0           ['conv5_block5_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block5_1_conv (Conv2D)   (None, 7, 7, 128)    81920       ['conv5_block5_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block5_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block5_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block5_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block5_concat (Concatena  (None, 7, 7, 672)   0           ['conv5_block4_concat[0][0]',    \n",
            " te)                                                              'conv5_block5_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block6_0_bn (BatchNormal  (None, 7, 7, 672)   2688        ['conv5_block5_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block6_0_relu (Activatio  (None, 7, 7, 672)   0           ['conv5_block6_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block6_1_conv (Conv2D)   (None, 7, 7, 128)    86016       ['conv5_block6_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block6_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block6_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block6_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block6_concat (Concatena  (None, 7, 7, 704)   0           ['conv5_block5_concat[0][0]',    \n",
            " te)                                                              'conv5_block6_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block7_0_bn (BatchNormal  (None, 7, 7, 704)   2816        ['conv5_block6_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block7_0_relu (Activatio  (None, 7, 7, 704)   0           ['conv5_block7_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block7_1_conv (Conv2D)   (None, 7, 7, 128)    90112       ['conv5_block7_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block7_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block7_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block7_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block7_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block7_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block7_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block7_concat (Concatena  (None, 7, 7, 736)   0           ['conv5_block6_concat[0][0]',    \n",
            " te)                                                              'conv5_block7_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block8_0_bn (BatchNormal  (None, 7, 7, 736)   2944        ['conv5_block7_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block8_0_relu (Activatio  (None, 7, 7, 736)   0           ['conv5_block8_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block8_1_conv (Conv2D)   (None, 7, 7, 128)    94208       ['conv5_block8_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block8_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block8_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block8_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block8_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block8_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block8_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block8_concat (Concatena  (None, 7, 7, 768)   0           ['conv5_block7_concat[0][0]',    \n",
            " te)                                                              'conv5_block8_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block9_0_bn (BatchNormal  (None, 7, 7, 768)   3072        ['conv5_block8_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block9_0_relu (Activatio  (None, 7, 7, 768)   0           ['conv5_block9_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block9_1_conv (Conv2D)   (None, 7, 7, 128)    98304       ['conv5_block9_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block9_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block9_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block9_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block9_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block9_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block9_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block9_concat (Concatena  (None, 7, 7, 800)   0           ['conv5_block8_concat[0][0]',    \n",
            " te)                                                              'conv5_block9_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block10_0_bn (BatchNorma  (None, 7, 7, 800)   3200        ['conv5_block9_concat[0][0]']    \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block10_0_relu (Activati  (None, 7, 7, 800)   0           ['conv5_block10_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block10_1_conv (Conv2D)  (None, 7, 7, 128)    102400      ['conv5_block10_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block10_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block10_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block10_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block10_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block10_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block10_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block10_concat (Concaten  (None, 7, 7, 832)   0           ['conv5_block9_concat[0][0]',    \n",
            " ate)                                                             'conv5_block10_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block11_0_bn (BatchNorma  (None, 7, 7, 832)   3328        ['conv5_block10_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block11_0_relu (Activati  (None, 7, 7, 832)   0           ['conv5_block11_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block11_1_conv (Conv2D)  (None, 7, 7, 128)    106496      ['conv5_block11_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block11_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block11_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block11_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block11_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block11_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block11_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block11_concat (Concaten  (None, 7, 7, 864)   0           ['conv5_block10_concat[0][0]',   \n",
            " ate)                                                             'conv5_block11_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block12_0_bn (BatchNorma  (None, 7, 7, 864)   3456        ['conv5_block11_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block12_0_relu (Activati  (None, 7, 7, 864)   0           ['conv5_block12_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block12_1_conv (Conv2D)  (None, 7, 7, 128)    110592      ['conv5_block12_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block12_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block12_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block12_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block12_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block12_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block12_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block12_concat (Concaten  (None, 7, 7, 896)   0           ['conv5_block11_concat[0][0]',   \n",
            " ate)                                                             'conv5_block12_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block13_0_bn (BatchNorma  (None, 7, 7, 896)   3584        ['conv5_block12_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block13_0_relu (Activati  (None, 7, 7, 896)   0           ['conv5_block13_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block13_1_conv (Conv2D)  (None, 7, 7, 128)    114688      ['conv5_block13_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block13_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block13_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block13_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block13_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block13_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block13_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block13_concat (Concaten  (None, 7, 7, 928)   0           ['conv5_block12_concat[0][0]',   \n",
            " ate)                                                             'conv5_block13_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block14_0_bn (BatchNorma  (None, 7, 7, 928)   3712        ['conv5_block13_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block14_0_relu (Activati  (None, 7, 7, 928)   0           ['conv5_block14_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block14_1_conv (Conv2D)  (None, 7, 7, 128)    118784      ['conv5_block14_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block14_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block14_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block14_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block14_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block14_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block14_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block14_concat (Concaten  (None, 7, 7, 960)   0           ['conv5_block13_concat[0][0]',   \n",
            " ate)                                                             'conv5_block14_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block15_0_bn (BatchNorma  (None, 7, 7, 960)   3840        ['conv5_block14_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block15_0_relu (Activati  (None, 7, 7, 960)   0           ['conv5_block15_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block15_1_conv (Conv2D)  (None, 7, 7, 128)    122880      ['conv5_block15_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block15_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block15_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block15_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block15_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block15_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block15_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block15_concat (Concaten  (None, 7, 7, 992)   0           ['conv5_block14_concat[0][0]',   \n",
            " ate)                                                             'conv5_block15_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block16_0_bn (BatchNorma  (None, 7, 7, 992)   3968        ['conv5_block15_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block16_0_relu (Activati  (None, 7, 7, 992)   0           ['conv5_block16_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block16_1_conv (Conv2D)  (None, 7, 7, 128)    126976      ['conv5_block16_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block16_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block16_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block16_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block16_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block16_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block16_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block16_concat (Concaten  (None, 7, 7, 1024)  0           ['conv5_block15_concat[0][0]',   \n",
            " ate)                                                             'conv5_block16_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " bn (BatchNormalization)        (None, 7, 7, 1024)   4096        ['conv5_block16_concat[0][0]']   \n",
            "                                                                                                  \n",
            " relu (Activation)              (None, 7, 7, 1024)   0           ['bn[0][0]']                     \n",
            "                                                                                                  \n",
            " avg_pool (GlobalAveragePooling  (None, 1024)        0           ['relu[0][0]']                   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 2)            2050        ['avg_pool[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 7,039,554\n",
            "Trainable params: 6,955,906\n",
            "Non-trainable params: 83,648\n",
            "__________________________________________________________________________________________________\n",
            "densenet None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_s=EarlyStopping(monitor='val_accuracy',patience=10,mode='max',restore_best_weights=True)"
      ],
      "metadata": {
        "id": "7U76REjHGao_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "model.fit(x=training_set, validation_data=validing_set, epochs=150,callbacks=([early_s]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFRoibWLtTMw",
        "outputId": "64afd15b-465b-48d5-a088-1e0743c7c468"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "37/37 [==============================] - 408s 10s/step - loss: 0.5615 - accuracy: 0.7308 - val_loss: 3.3031 - val_accuracy: 0.3897\n",
            "Epoch 2/150\n",
            "37/37 [==============================] - 30s 818ms/step - loss: 0.4335 - accuracy: 0.7947 - val_loss: 1.3005 - val_accuracy: 0.3757\n",
            "Epoch 3/150\n",
            "37/37 [==============================] - 30s 819ms/step - loss: 0.3952 - accuracy: 0.8373 - val_loss: 1.4355 - val_accuracy: 0.3817\n",
            "Epoch 4/150\n",
            "37/37 [==============================] - 30s 822ms/step - loss: 0.3868 - accuracy: 0.8237 - val_loss: 1.0712 - val_accuracy: 0.4851\n",
            "Epoch 5/150\n",
            "37/37 [==============================] - 30s 818ms/step - loss: 0.3748 - accuracy: 0.8365 - val_loss: 1.9943 - val_accuracy: 0.4294\n",
            "Epoch 6/150\n",
            "37/37 [==============================] - 30s 816ms/step - loss: 0.3353 - accuracy: 0.8671 - val_loss: 2.0727 - val_accuracy: 0.4095\n",
            "Epoch 7/150\n",
            "37/37 [==============================] - 30s 822ms/step - loss: 0.3298 - accuracy: 0.8646 - val_loss: 1.2533 - val_accuracy: 0.5586\n",
            "Epoch 8/150\n",
            "37/37 [==============================] - 30s 821ms/step - loss: 0.3186 - accuracy: 0.8646 - val_loss: 0.5898 - val_accuracy: 0.6859\n",
            "Epoch 9/150\n",
            "37/37 [==============================] - 30s 822ms/step - loss: 0.3108 - accuracy: 0.8688 - val_loss: 0.6569 - val_accuracy: 0.7416\n",
            "Epoch 10/150\n",
            "37/37 [==============================] - 30s 818ms/step - loss: 0.3211 - accuracy: 0.8620 - val_loss: 2.3203 - val_accuracy: 0.6640\n",
            "Epoch 11/150\n",
            "37/37 [==============================] - 30s 816ms/step - loss: 0.2943 - accuracy: 0.8782 - val_loss: 3.2537 - val_accuracy: 0.6203\n",
            "Epoch 12/150\n",
            "37/37 [==============================] - 30s 818ms/step - loss: 0.2756 - accuracy: 0.8893 - val_loss: 1.6517 - val_accuracy: 0.6779\n",
            "Epoch 13/150\n",
            "37/37 [==============================] - 31s 830ms/step - loss: 0.2873 - accuracy: 0.8850 - val_loss: 0.8985 - val_accuracy: 0.7276\n",
            "Epoch 14/150\n",
            "37/37 [==============================] - 30s 817ms/step - loss: 0.2746 - accuracy: 0.8918 - val_loss: 1.3758 - val_accuracy: 0.6978\n",
            "Epoch 15/150\n",
            "37/37 [==============================] - 30s 817ms/step - loss: 0.2843 - accuracy: 0.8816 - val_loss: 2.2069 - val_accuracy: 0.6859\n",
            "Epoch 16/150\n",
            "37/37 [==============================] - 30s 817ms/step - loss: 0.2554 - accuracy: 0.9046 - val_loss: 1.6119 - val_accuracy: 0.6203\n",
            "Epoch 17/150\n",
            "37/37 [==============================] - 30s 823ms/step - loss: 0.2690 - accuracy: 0.8961 - val_loss: 0.5136 - val_accuracy: 0.7654\n",
            "Epoch 18/150\n",
            "37/37 [==============================] - 30s 822ms/step - loss: 0.2693 - accuracy: 0.8927 - val_loss: 0.3025 - val_accuracy: 0.8728\n",
            "Epoch 19/150\n",
            "37/37 [==============================] - 31s 851ms/step - loss: 0.2447 - accuracy: 0.9037 - val_loss: 0.3062 - val_accuracy: 0.8767\n",
            "Epoch 20/150\n",
            "37/37 [==============================] - 30s 817ms/step - loss: 0.2653 - accuracy: 0.8952 - val_loss: 0.5155 - val_accuracy: 0.8052\n",
            "Epoch 21/150\n",
            "37/37 [==============================] - 30s 816ms/step - loss: 0.2399 - accuracy: 0.8995 - val_loss: 0.7366 - val_accuracy: 0.7018\n",
            "Epoch 22/150\n",
            "37/37 [==============================] - 30s 823ms/step - loss: 0.2494 - accuracy: 0.9037 - val_loss: 0.3125 - val_accuracy: 0.8827\n",
            "Epoch 23/150\n",
            "37/37 [==============================] - 30s 817ms/step - loss: 0.2372 - accuracy: 0.8961 - val_loss: 0.4483 - val_accuracy: 0.7594\n",
            "Epoch 24/150\n",
            "37/37 [==============================] - 30s 819ms/step - loss: 0.2301 - accuracy: 0.9029 - val_loss: 0.5883 - val_accuracy: 0.7913\n",
            "Epoch 25/150\n",
            "37/37 [==============================] - 30s 817ms/step - loss: 0.2347 - accuracy: 0.9003 - val_loss: 0.3354 - val_accuracy: 0.8549\n",
            "Epoch 26/150\n",
            "37/37 [==============================] - 30s 822ms/step - loss: 0.2221 - accuracy: 0.9131 - val_loss: 0.2755 - val_accuracy: 0.9046\n",
            "Epoch 27/150\n",
            "37/37 [==============================] - 30s 815ms/step - loss: 0.2221 - accuracy: 0.9080 - val_loss: 0.4210 - val_accuracy: 0.8151\n",
            "Epoch 28/150\n",
            "37/37 [==============================] - 30s 822ms/step - loss: 0.2456 - accuracy: 0.9003 - val_loss: 0.5180 - val_accuracy: 0.7813\n",
            "Epoch 29/150\n",
            "37/37 [==============================] - 30s 822ms/step - loss: 0.2225 - accuracy: 0.9080 - val_loss: 0.3687 - val_accuracy: 0.8330\n",
            "Epoch 30/150\n",
            "37/37 [==============================] - 30s 817ms/step - loss: 0.2411 - accuracy: 0.9072 - val_loss: 0.6763 - val_accuracy: 0.8091\n",
            "Epoch 31/150\n",
            "37/37 [==============================] - 30s 818ms/step - loss: 0.2087 - accuracy: 0.9208 - val_loss: 0.4693 - val_accuracy: 0.8330\n",
            "Epoch 32/150\n",
            "37/37 [==============================] - 30s 816ms/step - loss: 0.2072 - accuracy: 0.9191 - val_loss: 0.2986 - val_accuracy: 0.8907\n",
            "Epoch 33/150\n",
            "37/37 [==============================] - 30s 815ms/step - loss: 0.2400 - accuracy: 0.9089 - val_loss: 0.6666 - val_accuracy: 0.7177\n",
            "Epoch 34/150\n",
            "37/37 [==============================] - 30s 817ms/step - loss: 0.2145 - accuracy: 0.9182 - val_loss: 0.2749 - val_accuracy: 0.9026\n",
            "Epoch 35/150\n",
            "37/37 [==============================] - 30s 818ms/step - loss: 0.2413 - accuracy: 0.9080 - val_loss: 0.8341 - val_accuracy: 0.7555\n",
            "Epoch 36/150\n",
            "37/37 [==============================] - 30s 825ms/step - loss: 0.2110 - accuracy: 0.9199 - val_loss: 0.4093 - val_accuracy: 0.8091\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f689007c710>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction=model.predict(testing_set)\n",
        "classes_x=np.argmax(prediction,axis=1)\n",
        "classes_x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZOYy7N85_YO",
        "outputId": "4a057699-518f-410f-c535-5be02d692ab2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "       1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
              "       1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "       0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "       1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1,\n",
              "       1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "       1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0,\n",
              "       1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cf = confusion_matrix(y_true= true_labels, y_pred= classes_x)\n",
        "score = accuracy_score(y_true= true_labels, y_pred=classes_x)\n",
        "print(cf)\n",
        "print('the model performane is: ', score*100, \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ER5cq5f1ysLm",
        "outputId": "08e10f29-bb5e-4d5a-e11c-f2c1b69410da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[71 35]\n",
            " [41 23]]\n",
            "the model performane is:  55.294117647058826 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(true_labels, classes_x,target_names=label_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILWbLkN8yvH3",
        "outputId": "c1aaeee3-09f8-415d-9c93-64843c8b206d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    abnormal       0.63      0.67      0.65       106\n",
            "      normal       0.40      0.36      0.38        64\n",
            "\n",
            "    accuracy                           0.55       170\n",
            "   macro avg       0.52      0.51      0.51       170\n",
            "weighted avg       0.54      0.55      0.55       170\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cf = confusion_matrix(y_true= true_labels, y_pred= classes_x)\n",
        "score = accuracy_score(y_true= true_labels, y_pred=classes_x)\n",
        "print(cf)\n",
        "print('the model performane is: ', score*100, \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9BL-6l07EBM",
        "outputId": "e54b2b32-3ec5-4c8b-e2fa-7a69de6dc676"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[76 29]\n",
            " [39 26]]\n",
            "the model performane is:  60.0 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(true_labels, classes_x,target_names=label_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MX6Se4Z-HaZW",
        "outputId": "c68df2bb-53c0-412a-eb19-edaf3c0aba1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    abnormal       0.66      0.72      0.69       105\n",
            "      normal       0.47      0.40      0.43        65\n",
            "\n",
            "    accuracy                           0.60       170\n",
            "   macro avg       0.57      0.56      0.56       170\n",
            "weighted avg       0.59      0.60      0.59       170\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# keras densenet121"
      ],
      "metadata": {
        "id": "jt5djaZg62cM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1=tf.keras.applications.DenseNet121(include_top=True,\n",
        "    weights=None,\n",
        "    input_tensor=None,\n",
        "    input_shape=(224, 224, 3),\n",
        "    pooling='avg',\n",
        "    classes=2)\n",
        "# base_inputs = model1.layers[0].input\n",
        "# base_output = model1.layers[-2].output\n",
        "# output = layers.Dense(2,activation='sigmoid')(base_output)\n",
        "# model1 = keras.Model(base_inputs, output)\n",
        "# print(\"densenet\",model1.summary())"
      ],
      "metadata": {
        "id": "yiBg_8z851x8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction1=model1.predict(testing_set)\n",
        "classes_x1=np.argmax(prediction1,axis=1)\n",
        "classes_x1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSxBQedw5--l",
        "outputId": "b5fd32e3-680a-4e3a-a9e9-745c57fe3f94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cf1 = confusion_matrix(y_true= true_labels, y_pred= classes_x1)\n",
        "score1 = accuracy_score(y_true= true_labels, y_pred=classes_x1)\n",
        "print(cf1)\n",
        "print('the model performane is: ', score1*100, \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-W1v8tM6X_t",
        "outputId": "9766cd69-139a-48c8-c539-554283368695"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[106   0]\n",
            " [ 64   0]]\n",
            "the model performane is:  62.35294117647059 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(true_labels, classes_x1,target_names=label_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVWFbc1B6eBH",
        "outputId": "1eec9144-9342-48b3-9c16-e7006e531147"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    abnormal       0.00      0.00      0.00       106\n",
            "      normal       0.38      1.00      0.55        64\n",
            "\n",
            "    accuracy                           0.38       170\n",
            "   macro avg       0.19      0.50      0.27       170\n",
            "weighted avg       0.14      0.38      0.21       170\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#effecientnet"
      ],
      "metadata": {
        "id": "BLFTTvv_68vb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_e0=tf.keras.applications.EfficientNetB0(\n",
        "    include_top=True,\n",
        "    weights=None,\n",
        "    input_tensor=None,\n",
        "    input_shape=(224,224,3),\n",
        "    pooling='avg',\n",
        "    classes=2,\n",
        "    classifier_activation=\"sigmoid\"\n",
        "\n",
        ")\n",
        "# base_inputs_e0 = model_e0.layers[0].input\n",
        "# base_output_e0 = model_e0.layers[-2].output\n",
        "# output_e0 = layers.Dense(2, activation='softmax')(base_output_e0)\n",
        "# model_e0 = keras.Model(base_inputs_e0, output_e0)\n",
        "print(\"effecient\",model_e0.summary())"
      ],
      "metadata": {
        "id": "FAIlq8oi7EKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_e0.compile(optimizer='adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "model_e0.fit(x=training_set, validation_data=validing_set, epochs=150,callbacks=([early_s]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "804ksm22-2es",
        "outputId": "28469367-a17e-42c0-9b73-6e94afb8df42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "37/37 [==============================] - 34s 650ms/step - loss: 0.5014 - accuracy: 0.7896 - val_loss: 4.2348 - val_accuracy: 0.3817\n",
            "Epoch 2/150\n",
            "37/37 [==============================] - 22s 603ms/step - loss: 0.4288 - accuracy: 0.8203 - val_loss: 3.7268 - val_accuracy: 0.3817\n",
            "Epoch 3/150\n",
            "37/37 [==============================] - 22s 603ms/step - loss: 0.3877 - accuracy: 0.8416 - val_loss: 4.2903 - val_accuracy: 0.3817\n",
            "Epoch 4/150\n",
            "37/37 [==============================] - 22s 600ms/step - loss: 0.3771 - accuracy: 0.8501 - val_loss: 4.3136 - val_accuracy: 0.3817\n",
            "Epoch 5/150\n",
            "37/37 [==============================] - 22s 599ms/step - loss: 0.3582 - accuracy: 0.8688 - val_loss: 4.4634 - val_accuracy: 0.3817\n",
            "Epoch 6/150\n",
            "37/37 [==============================] - 22s 600ms/step - loss: 0.2940 - accuracy: 0.8867 - val_loss: 4.4282 - val_accuracy: 0.3817\n",
            "Epoch 7/150\n",
            "37/37 [==============================] - 22s 599ms/step - loss: 0.2452 - accuracy: 0.9114 - val_loss: 4.6153 - val_accuracy: 0.3817\n",
            "Epoch 8/150\n",
            "37/37 [==============================] - 22s 596ms/step - loss: 0.2306 - accuracy: 0.9191 - val_loss: 5.3124 - val_accuracy: 0.3817\n",
            "Epoch 9/150\n",
            "30/37 [=======================>......] - ETA: 3s - loss: 0.1493 - accuracy: 0.9432"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-c7f916a3c80b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_e0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_e0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvaliding_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_s\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1219\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1220\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1221\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1222\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    434\u001b[0m     \"\"\"\n\u001b[1;32m    435\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    293\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m       raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    314\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1102\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    548\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1147\u001b[0m     \"\"\"\n\u001b[1;32m   1148\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1113\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1115\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1116\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_e0=model_e0.predict(testing_set)\n",
        "classes=np.argmax(prediction_e0,axis=1)\n",
        "classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPcGqYX28MXe",
        "outputId": "0f11f950-4ad5-47a5-95c1-0a44fe08ae6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cf_e0 = confusion_matrix(y_true= true_labels, y_pred= classes)\n",
        "score_e0 = accuracy_score(y_true= true_labels, y_pred=classes)\n",
        "print(cf_e0)\n",
        "print('the efficient performane is: ', score_e0*100, \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxFpubNJ8NAN",
        "outputId": "71f2ec26-397e-4e7e-bb9b-f4b83c745089"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[106   0]\n",
            " [ 64   0]]\n",
            "the efficient performane is:  62.35294117647059 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(true_labels, classes,target_names=label_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEQn4SbF8Mag",
        "outputId": "612063f5-0688-4180-88ef-16c096dadff3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    abnormal       0.62      1.00      0.77       106\n",
            "      normal       0.00      0.00      0.00        64\n",
            "\n",
            "    accuracy                           0.62       170\n",
            "   macro avg       0.31      0.50      0.38       170\n",
            "weighted avg       0.39      0.62      0.48       170\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "aHTtc04RPqGz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}